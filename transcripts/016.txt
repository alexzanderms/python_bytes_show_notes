Python Bytes Transcript
Episode #16: Postmodern Python and Open-Source Financial Awards
Michael KENNEDY: This is Python Bytes, Python headlines and news delivered directly to your earbuds. This is Episode #16, recorded on March 6, 2017.  This is your host, Michael Kennedy, here with my co-host, Brian Okken. 
Hey, Brian.
Brian OKKEN: Hello.
KENNEDY: I’m excited to talk about another week’s worth of Python news. Before I do, I want to say thank you. Thanks to Rollbar for sponsoring this episode. 
So, you’ve got the first item and it’s kind of an artistic, postmodern-type of thing, but with error handling.
OKKEN: Yeah, there’s an article on Journal Panic, and I have to say that’s a cool name for a website. It’s called, “Postmodern Error Handling in Python 3.6.” I guess you could consider it error handling; it’s mostly how to structure your code so you don’t make mistakes and let the language help you out. I highly recommend the read. The examples are hilarious. You go through some error prevention using Enum classes and the NamedTuple class, which I have to admit I just learned about. I’ve used NamedTuples, but I only learned about the class recently. And using Type Hints mypi to help avoid errors in your code.
KENNEDY: Yeah, I think it’s really nice. Some of these are 3.4 only, right? Enum Support was added in Python 3.4, which is pretty cool. There was somebody who commented, basically the idea was, they were talking on some message board or something about, ‘How would you handle this kind of error? Say, it’s not true or false: it’s true, false or maybe, right?’ They proposed this 3-step type of thing. Somebody said, ‘Well, if you were using Rust, you could have Enums.’ And he says, ‘Well, I’m using Python 3.x so, I have Enums.’ That was pretty funny. 
OKKEN: It’s nice, I only noticed this this morning. The tail end of this article references your Talk Python, so that’s cool.
KENNEDY: Yeah, that’s awesome. Thanks for referencing that. 
NamedTuples are so excellent. I really started using NamedTuples a lot. I think they’re great. Type Hints…
OKKEN: NamedTuples I’ve been using a lot because they’re very convenient but the syntax is a little ugly. The NamedTuple class actually makes the syntax a little bit cleaner. I think that’s cool.
KENNEDY: Of course, mypi, which is great for static type hinting, I guess, type discovery.
OKKEN: In the show notes I’m also including a link to another article on mypi and Type Hints called, “Python Type Annotations.” It’s from the Cactus Group and it’s another pretty good tutorial for Type Hints in mypi. 
KENNEDY: Excellent.
So, the next one we’re going to talk about, this is sort of a sequence that I’m going to go through here; one leads to another in a very cool way. Mid last year, mid-2016, Mozilla awarded a little over half a million dollars to 9 open source projects, just in Q2 (second financial quarter) 2016. That’s really cool, right?
OKKEN: That’s very cool. 
KENNEDY: So, they have these things they call tracks. “Foundational Technology” tracks and “Mission Partner” tracks. What they do is, the go out and they find open source projects that somehow that success of that open source project furthers the goals of Mozilla. An open source, free web that Firefox and other things run well on, right? 
So, why is this on the Python thing? Well, they chose a really cool project. They’ve said that they’ve already funded 8 projects for $385,000 and they’re still considering more. They have applications available for what is called a “Mission Partner.” If you have an open source project and you think the mission of your project lines up well with Mozilla, maybe that can be your job; maybe Mozilla would pay you to work on your project. 
First of all, just check this out. That’s awesome.
OKKEN: Yeah, definitely. That’s cool.
KENNEDY: Yeah, they also have a track on “Secure Open Source” for improving the security of open source software. 
The one that’s really interesting to me, and I think the audience, is the “Foundational Technology” track. One of the things that was awarded there, one of the projects, was PyPy, the alternate implementation that’s a JIT for Python. It’s been working with Python 2.7, but it’s not really great with Python 3.x. It’s iffy and only some of the features are supported and so on. They received $200,000 in donations to make that happen.
OKKEN: That’s really great. That will make PyPy a lot more compelling if they get that updated to 3.x. 
KENNEDY: Absolutely. It’s one thing to say we’re on 2.7 and then we’ll move in a little bit, it’s another to say that we’re going to build on a technology that has no Python 3.x story; that’s a pretty serious blockade. Now they have an Alpha version of PyPy 3.5 and it’s looking really good. More on that in another section.
OKKEN: Okay, cool. 
Speaking of announcements, I’ve just been sort of following what Intel’s been doing. I think Talk Python had an Intel episode.
KENNEDY: Yeah, we had a great conversation about how Intel is actually thinking about the architecture of their chips, so that it lines up the way that Python executes code. 
OKKEN: They’re continuing working on this. The announcement that we’re linking to is an announcement from Intel that says, “Intel Distribution for Python 2017 Update 2 accelerates five key areas for impressive performance gains.” It looks like they’re continuing on. This version that they’ve got is somethings that is a special release of Python. It’s compiled knowing that it’s going to run on an Intel architecture. It supports Windows, Linux, OSX and it’s got 3.5. Oddly 3.6 is missing. What’s going on, guys? 
But the improvements are pretty cool. There was a comment about widespread optimizations for NumPy and SciPy FFTs with stated, ‘Sometimes it could possibly improve 60x over Update 1.’ So, they really are hammering in to try to make this fast for some intensive stuff. 
KENNEDY: Yeah, that’s really cool if you’re doing any sort of computational stuff involving NumPy and SciPy. That’s pretty amazing performance. To make it basically as fast as Native C and the Intel high performance C libraries, that’s really something.
OKKEN: They also touched on some improvements in memory management. What I thought was cool was arithmetic and transcendental expressions from NumPy are able to use multi-cores now. I just like that because I don’t know what a transcendental expression is. I think that’s what your face looks like when you’re meditating maybe. 
KENNEDY: Yeah, that sounds awesome. It already sounds intriguing. What good naming and nomenclature. 
OKKEN: I think it’s neat that they’re working on it and that it’s not just for paid people, there’s a free stand-alone version.
KENNEDY: Yeah, that’s very cool. 
The next one I want to talk about is also about performance. But before we do, I want to talk about errors. We don’t like errors in our web apps, do we?
OKKEN: Definitely not.
KENNEDY: So, our sponsor this week, Rollbar, will totally help you take the pain out of errors and solve that problem. I used them on my own sites, I know many people out there do as well. What you do is, you basically install, with just a few lines of code, Rollbar into your Flask, Django, Pyramid web apps. If there is ever an error, you’ll get a notification, you’ll get a report containing all the details that you need. ‘Here’s some kind of crash. Here is the traceback. Here’s the browser and the platform.’ Everything that was possibly passed in the whole web request, right there for you. You’ll get notified straight away if there are any errors and you won’t even, probably, have to debug it. You’ll just have to look and think, ‘Oh, dear. We have to go fix this.” Definitely check them out at Rollbar.com. I use them, I think they’re great. 
OKKEN: Wonderful. 
KENNEDY: Absolutely. And thanks for sponsoring the show guys. 
So, let’s talk about performance. This is a follow-on from the Mozilla one. The guys at PyPy released some performance graphs and stuff from their work on implementing Python 3.5. They said, ‘Look, the core new thing that we need to work on is this whole asyncio story.’ That’s the kernel of the new stuff in Python 3.5. So, what they did is they said, ‘Let’s put out some numbers on how we’re doing in that area.’ I want to say thanks to Guy Fighel (@guyfig) who sent this over to us and said, ‘Hey, you should talk about this.’ 
They said, ‘Look, we’re going to take things like Tornado, asyncio, Curio, GEvent and Twisted. We’re going to run them on PyPy 3.5 and see how they do.’ And they did pretty well, actually. They have a bunch of graphs and they’re basically 5 to 10 times faster than CPython on all of those workloads. If you could run 5 times fewer servers because you don’t need them, with pretty much the same code, that would be pretty handy, right?
OKKEN: Definitely, that’s cool.
KENNEDY: There’s a lot of interesting things. I feel like this whole, ‘Let’s leverage asyncio plus something else’ is really blowing up these days. We’ve had a lot of this stuff happening in the web frameworks with japronto, with async, aiohttp, with Sanic, with this. There’s a lot of stuff going on right now trying to something with async and await and asyncio to make things faster. I think we’ll continue to hear good stories around this. 
OKKEN: It’s cool that it keeps progressing.
KENNEDY: Yeah, absolutely. 
What’s unclear is which one of these is going to be the path. Is japronto going to be the way to go? Is aiohttp the way to go? There’s Sanic; there’s so many flowers blooming it’s kind of tough to pick the right one because they all seem so promising in slightly different ways. 
OKKEN: And from somebody that’s trying to set up a project that needs to pick one right now, I can see how that would be a little confusing. But I don’t think these are terribly different things. I don’t know; maybe it is. I have no idea what it would be like if you went with Sanic or something and then Sanic disappeared for some reason and you needed to switch, how difficult. At the very least, having a lot of people look at it and try to make things faster is a good thing. 
KENNEDY: Yeah, absolutely.
OKKEN: Ned Batchelder is the guy that supports coverage.py, which most people use to look at coverage of their code. He wrote a couple articles called, “A Tale of Two Exceptions” and he’s got 2 parts. What was going on was, he was trying to get all of his tests suites to run on Jython and there was – I don’t know the details of the problem – there was an issue with the Jython that made it so that the recording mechanism doesn’t quite work or doesn’t work. It’s not a crucial part of the system of coverage so he wanted to skip the tests that depended on that while running on Jython. 
And, wow, it’s an interesting tale. He walks you through the entire thought process of why he chose different attempts and maybe inheriting from the exception class and picking another base for the exceptions that he covered, exceptions used. He kind of ends up leaving it not quite wrapped up at the end of the first post, then with some feedback from some readers on the first post, came up with a way to use decorators and metaclasses to apply the decorators to be able to skip those more effectively. It’s a couple pretty cool articles. 
KENNEDY: Yeah. Nice work, Ned. That’s a nice write up. 
So, what do you have to do if you have to do coverage on Jython? You basically run it and collect the report and then you have to actually process it with CPython? 
OKKEN: Well, I’m sure there’s enough support to understand your coverage, but the coverage package has a whole bunch of cool stuff like generating HTML reports and a lot of other types of reports. It’s possible that those are the parts that are missing. 
KENNEDY: Yeah, this is definitely an interesting use of metaclasses, there’s some multiple inheritance thrown in there. There’s a lot of stuff in this, actually.
OKKEN: One of the things that I wanted to point out was, I’ve seen a lot of articles with people saying, ‘Look, I’ve got this cool solution I came up with to this particular problem.’ It’s very refreshing to see somebody say, ‘I’ve got a sticky problem with a solution that I’m still not quite happy with and here it is.’ It’s nice. 
A good takeaway from it is, he didn’t present all of the code that he could have. The code that he puts in the articles, he boiled those down so that you can understand the problem but they’re not huge. That’s extra work on his part but it makes for a nice, quick read. 
KENNEDY: Yeah, a lot of people ask me, ‘How did you come up with this type of problem?’ or ‘Could you explain the thinking that got here because I don’t see how you got from A to B?’ This is a good example of laying that out. I think it’s nice. 
OKKEN: Also, it prevents people from saying, ‘Well, why didn’t you try X?’ Because he already did and he’s showing it. 
KENNEDY: Check that one out. It’s very cool. The last one is also about async and await and it’s also about performance. But this is a totally different story. 
All this stuff that we’ve been talking about, the Mozilla thing, the PyPy tests that they ran, the majority of those were testing web frameworks. So, I want to write a web server that’s going to process requests, let’s do it faster. This is totally different. 
This is about, ‘I want to consume services really quickly.’ The aiohttp library actually has some really cool stuff to do this that I just learned about, so I thought I would share it with you guys. 
OKKEN: Wow, that’s great.
KENNEDY: So, you’ve heard of Requests, right? The most downloaded package ever?
OKKEN: Well, definitely.
KENNEDY: So, we all know about requests. It’s downloaded like 7 million times a month or something insane. Well, aiohttp has a similar library as Requests. It’s actually very similar in the way they use it and its features and so on. However, Requests itself, you can’t await it in async and await. It doesn’t use some sort of deferred io callback in order to complete your request, it’s just blocks. So, the big difference with aiohttp is you can await the responses at different levels. You can do it on the network calls, you can do it on the parsing. It even has a file-based thing so you can await right into files. This person write up a cool little example, putting those both side-by-side and the code is quite similar. If you did not have async and await the code would be really nasty looking, but because you do it becomes similar. 
What we’re going to do is I’m going to get a bunch of stats about basketball players in the NBA. There’s an API for that, apparently. So, it’s going to run some code and it’s going to collect all the stats and it took 12 minutes on Request using aiohttp and aio files. It took 22 seconds. That’s really awesome, right? 33 times faster. 
OKKEN: Definitely. 
KENNEDY: And the code is virtually identical. The difference is basically, you begin a request from the API and normally you’re just waiting on the network. You’re waiting for a response, right? But you should be able to kick off a whole bunch more of those requests until one of them comes back and you have to process them. It doesn’t even use threads to pull this off, it just used io callback type things. 
OKKEN: Really? Okay. 
KENNEDY: Yeah, pretty awesome. So, this is definitely one of those things that shows the power of Python 3.5 and up. 
OKKEN: Yeah, it’s nice to have it one the client side, too. We’ve got a lot of examples recently of async and await on the server side. 
KENNEDY: Absolutely. 
So, I want to squeeze one more piece of news in here before we wrap it up. I talk a lot about PyPI on Talk Python. We grab a lot of packages from there and talk a lot about them here on Python Bytes. There’s quite a milestone that just passed there, 2 days ago, 3 days ago, something like that. 
OKKEN: A very cool milestone.
KENNEDY: A very cool milestone. There are now over 100,000 packages on PyPI. How cool is that? 
OKKEN: That’s very cool. I wonder if the person who got the 100,000th one in there, if they know about it. 
KENNEDY: If they know that they are the one who put it over the top? Yeah, we need to find out. We need to contact Donald Stuft and see if he knows, if he can find out. I bet there’s some sort of query that can be done that will answer that question.
OKKEN: That’d be cool.
KENNEDY: That’d be very cool.
Alright, that’s it for me. Got any news to share with anyone? 
OKKEN: Just that I’ve been in the throes of trying to switch over the Test and Code podcast to a new domain name, testandcode.com. Hopefully, it should be seamless for everyone who subscribed, just if you see anything. 
KENNEDY: We should let you know. Very cool, congrats. You have a whole new system driving it, right? Like a whole new website? 
OKKEN: It’s basically hands-off for me. I’m letting the Software as a Service do most of the work for me. 
KENNEDY: That sounds very relaxing. 
OKKEN: I have @testpodcast as the Twitter thing with a bunch of followers. I also have @testandcode as a Twitter but there’s only like 4 people following, so I have no idea what to do with that. 
How about you? Got anything you want to announce? 
KENNEDY: No, not too much. I’m just continuing to work on classes and create more online classes. I actually have a surprise one coming that I’m sure will be unexpected but I’m sure will be fun. Maybe next week I can talk about it. 
OKKEN: I’ll practice my surprised voice. 
KENNEDY: Thank you, everyone, for listening. Brian, great to talk to you as always.
OKKEN: As always. See ya.
KENNEDY: Thank you for listening to Python Bytes. Follow the show on Twitter via @pythonbytes and get the full show notes at pythonbytes.fm. If you have a news item you want featured, just visit pythonbyes.fm and send it our way. We’re always on the lookout for sharing something cool. On behalf of myself and Brian Okken, this is Michael Kennedy. Thank you for listening and sharing this podcast with your friends and colleagues. 