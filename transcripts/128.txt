00:00:00 KENNEDY: Hello and welcome to Python Bytes, where we deliver Python news and headlines directly to your earbuds. This is Episode 128, recorded April 30th, 2019. I'm Michael Kennedy.
 
00:00:12 OKKEN: And I'm Brian Okken.
 
00:00:12 KENNEDY: And this episode is brought to you by Digital Ocean. They're great supporters of the show. Please check them out at pythonbytes.fm/digitalocean and get $100 free credit. Brian, I am super excited.
 
00:00:22 OKKEN: Are you? What about?
 
00:00:24 KENNEDY: We are on PyCon eve.
 
00:00:26 OKKEN: Yeah, but when is this going to go out though? I mean ...
 
00:00:31 KENNEDY: I think this is going out before PyCon. And this still will be out during PyCon, if nothing else. We're going to rush.
 
00:00:36 OKKEN: Yeah, I'm excited that I don't have to pack my banner thing this time.
 
00:00:40 KENNEDY: I know. We're going to be at the JetBrains booth and they're going to have all that stuff set up for us, so we can just roll in like a normal attendee with a relatively small amount of gear in tow. It'll be great.
 
00:00:51 OKKEN: Yeah, I want people to show up at 6:30 at the Thursday night thing because I'm going to be recording at 6:30 live. So, stop by there.
 
00:00:56 KENNEDY: Awesome. Yeah, I feel like with the JetBrains stuff, and just independent of that, we're going to be doing a lot of live recording there for Test and Code, for Talk Python, and Python Bytes, and you know, we'll try to get the word out about that. But it's going to be a lot of fun. For sure. So, let's just jump right into the first one here. I see this one is well within your wheelhouse.
 
00:01:15 OKKEN: Yeah. I forgot about the order. Yes, there's an article from Adam Johnson called "Solving Algorithmic Problems in Python with Pytest." And yes, Pytest is definitely my wheelhouse. I like the highlighting of this. Here's the idea, you've got coding challenges, especially algorithmic ones, like Project Euler or Advent of Code, or others. There's lots of coding challenges projects. And doing those goes through one example and shows how to translate the project description, the problem description, and the specification into some quick little tests. And they're like showing it how small tests can be. Just testing one aspect of the answer, so that the example goes through basically, yeah, it's a little bit of a TDD practice thing of coming up with some tests to test the test case, going through an exercise translating all the specification into tests, and then just working through it. Looking at all the failures and failure cases, especially, so one of his examples was to just create a stub answer, just the function you're trying to actually write, just have it return some constant, and then build that up. And it's a little bit of a TDD practice, but also just practice writing tests to do these sort of projects. And it's a short article and I really liked it.
 
00:02:31 KENNEDY: Yeah, it's a cool way to explore solving some problems with the whole Project Euler thing, and it's also a cool way to get some experience working with pytest. And I feel like these types of problems are pretty good entry-level pytest-type problems. It's not, well we have the website and we want to make sure the user can register, and like, okay well, how can I mock out the database call and then stub out the e-mail service. Like all that complicated stuff, right? Where here it's like a pretty constrained problem. Like, find the minimum path amongst these bridges or whatever the problems, like these sort of mathematical algorithmic ones.
 
00:03:07 OKKEN: Yeah, and his example is super easy. It's just returning the minimum value in a list as long as it's positive.
 
00:03:13 KENNEDY: Nice.
 
00:03:14 OKKEN: And it's easy to get your head around. And actually I love doing little practice things like that.
 
00:03:18 KENNEDY: Cool. Yeah, I do too and I'm a fan of Project Euler. So, quite cool. This next on that I have, I feel like maybe we haven't really discussed it enough but it has to do with Python Packaging. Do you think?
 
00:03:31 OKKEN: Oh yeah, we haven't covered Packaging much.
 
00:03:33 KENNEDY: No, so it's good that it's finally coming up on the show. This one is interesting because it's kind of like a meta-packaging tool. So we've talked about the pyproject.toml, we've talked about the pipfile.lockfile, requirements.txt, poetry, all these things, right. Well, this one that I found, or was actually sent to us by @dreigelb on Twitter, is called DepHell, as in Dependency Hell. So, he just comes out and says it, right. Like there's flames on the logo. Come on. So, the idea is that it will let you work in these different modes and even automatically translate between them. So one of them is like, hey, we have a setup.py for managing this particular type of project. I would rather have a pyproject.toml file that expresses the same thing. And you just run a command line against that project, and it'll generate the pyproject.toml based on the current setup in your project.
 
00:04:32 OKKEN: Oh nice.
 
00:04:33 KENNEDY: Yeah, so if you want to, say, switch it to poetry, you can run a command and it'll switch it to poetry. If you want to switch it over to pipenv, fine, and you run that, and it'll do it. So, that's one of the things it does. It's pretty cool in that, it'll let you use all these different things. It doesn't really try to replace them, but it more tries to like tie them together, right. Like I've grabbed a project, but maybe it's not in my the tooling that I like. It's pretty easy to extend. It's really quite nice. I like this ability to translate between them. It also has some of the features of pipenv, so it'll create like a shell. It'll install your command line utilities into their own isolated virtual environment like, pytest could be in its own environment that has nothing to do with your project, but is available to run against your project. Things like that.
 
00:05:19 OKKEN: Yeah, nice.
 
00:05:20 KENNEDY: Yeah, so not too much else to say I guess. It's based on asyncio, so that means it only supports modern Python. That's pretty awesome. So, it's super fast. All of its network calls and stuff are made asynchronously. And yeah, it's pretty good.
 
00:05:35 OKKEN: I think something like this would be great for a project that has a maintainer that doesn't care about pipenv or something, is fine with requirements or whatever they're using. But there's a couple of maintainers that really like pipenv and want to have the pipfile around and the lockfile.
 
00:05:52 KENNEDY: Yeah, that's interesting. Like you could have one of them that's the source of truth and then use this tool to generate the others if you'd rather work that way, right? Yeah, you could even do that as part of an automated build, right? Delete the pipfile and then recreate it as part of the build and then check that back in, who knows?
 
00:06:09 OKKEN: Yeah, okay. Cool.
 
00:06:10 KENNEDY: Yeah, pretty cool. This next one that you found is a bit of a rant, huh?
 
00:06:14 OKKEN: Yes, definitely. Mike Croucher, which I'm not sure what he does. I think he works ... He writes a lot of great articles and I come across his name every once in a while, so thanks, Mike. This rant even says it in the name, "Python rant: from foo import is bad." But basically just import * is bad. I thought this was just done, that nobody did this anymore, but I actually see quite a bit of code that still has this in it. And I was actually looking for different blog posts. There's some blog posts that have great advice in Python, but the example code has import * and I'm not going to point people to that because it's just a bad practice. And his example, for instance, is the square root function, sqrt. If you just have result = sqrt(-1), what does that mean? You don't know what it means because you don't know where that came from. And there's some really confusing examples that he's showing how it may have been from the math library, it may have been numpy, or cmath, or scipy, or sympy. All of them have the same function name and we like namespaces, but when you use import * you throw away the namespace ability. You just import everything into your current namespace. So, don't do that.
 
00:07:33 KENNEDY: Yeah. I like the hat tip to Full Metal Jacket. This is my rant on import *. There are many like it, but this one is mine. This one's my own. You know, I totally like this as well. I'm a big fan of having super explicit namespaces to like really tell where something comes from. In fact, I typically try to shy away from thing import Something. Not just import *, just, even that, it's more like, import this module than module.function, module.class. You know, sometimes if it's like deeply nested I might do import thing as just the last part of that name. But you know, something to give you a hint, like, where the heck did this come from?
 
00:08:15 OKKEN: Right, and like for instance, the convention is to import numpy as np.
 
00:08:21 KENNEDY: 'Cause numpy is really long to type.
 
00:08:25 OKKEN: I know. However, you're using a ton of it and so, yeah.
 
00:08:27 KENNEDY: Yes.
 
00:08:29 OKKEN: There are conventions and if you notice the conventions, just follow them.
 
00:08:33 KENNEDY: Yeah, absolutely.
 
00:08:34 OKKEN: I'm with it too, so sometimes when I'm refactoring some code or trying to understand it, it's frustrating when somebody has a bunch of from library import like five different functions.
 
00:08:44 KENNEDY: Yeah. You know, it's not terrible if you've got something like Visual Studio Code or you've got PyCharm, and you can like go to definition or you hover over it and it'll say more. But if you see it in a blog post, or you see it printed, or you see it in like a Gist, or somewhere that doesn't have like understanding of the environment, then you're like okay what is that, right? So just think about it.
 
00:09:05 OKKEN: Yeah. I actually kind of wish they'd deprecate it, but that's probably never going to happen.
 
00:09:09 KENNEDY: Yeah, probably not. I talked about Digital Ocean at the top. Let me just tell you about something that's new and cool. Brian, are you familiar with GitHub Actions?
 
00:09:17 OKKEN: I just heard a little bit about them.
 
00:09:19 KENNEDY: Yeah, same. I haven't really done anything with them. But it's basically, GitHub Actions are like a series of workflows that can be triggered when you do like a push to a repository, you create a release, or you create an issue. And it runs a series of actions that then can kick off CI or do other sorts of tasks. Well, Digital Ocean has come out with GitHub Actions for Digital Ocean. So you can do really cool things. Like, I would like to upgrade my Kubernetes cluster anytime I push to the release branch or the master branch in my GitHub repo and just bake that straight into GitHub.
 
00:09:55 OKKEN: Oh wow.
 
00:09:55 KENNEDY: Right. Just the fact of you doing a commit or the integration test passing or whatever. You know, whatever you want to do with the GitHub Actions you can set that up. So there's a special GitHub Actions for Digtial Ocean and yeah, check them out. Really cool stuff they have on their blog post, they have something about working with the Kubernetes service there and then using the GitHub Actions to sort of keep it always up to date. So check them out at Pythonbytes.fm/digitalocean. Get $100 free credit for new users. I feel like GitHub Actions or something I just want to learn in general. How about you?
 
00:10:26 OKKEN: Definitely, yeah. It seems like something that could help out with the workflows.
 
00:10:29 KENNEDY: Yeah, absolutely. Cool, well, this next one that I want to talk about is not super new, but I don't know how we've gone this long really without talking about it. So, Dask. Dask is a way to natively scale Python. When I first heard about it, I first heard about it, I thought okay, well Dask is like this thing that takes data science workloads and run them on clusters. And the reason I didn't get super excited is like, well I don't do that much data science, and I don't have enough that require clusters to run. They're usually pretty small, little graphy things or something if I'm doing any data science. However, I recently had Matthew Rocklin, who's behind Dask, on Talk Python in Episode 207, and we talked a lot about it and there's actually some really cool stuff. I think more applicability to more people than I first realized. So basically the idea is like, Dask will take the NumPy, SciPy sort of stack and scale it out. All right, so you have NumPy, you have Pandas, you have scikit-learn on code, all that. So there's Dask versions of NumPy arrays and panda data frames. So there's like Dask data frames. What you can do is just work with those, basically the same API, but instead of working just locally, it will work with them on the cluster. So suppose you have like three terabytes of data you need to process and it can't fit into RAM, so you can't just load it up into a NumPy array or a panda data frame, but you can tell Dask to process and it'll share it across the cluster and do all the work and the computation and the cross-server communication that you need. Isn't that cool?
 
00:11:58 OKKEN: That is neat.
 
00:11:59 KENNEDY: So it sounds really neat and that workload to me, doesn't really help that much 'cause I don't have to do a whole lot. But I know some people that it'll be super valuable for. You can also just run Dask locally on your machine and it will create like a little mini cluster that runs locally and it'll use like threads and processes and what not. And it'll even let you process more data locally than will fit into RAM, and do like lazy loading, and all sorts of interesting stuff there. So, pretty cool. It even lets you escape the GIL. So you get better parallelism, even on your own computer. And it runs arbitrary Python code, not just NumPy and Pandas, even though that's its main use.
 
00:12:36 OKKEN: That's actually pretty darn cool.
 
00:12:38 KENNEDY: Yeah, that's what I thought. So I decided to make it one of our topics for today.
 
00:12:41 OKKEN: Yeah. The large file stuff, I definitely hit that occasionally. And I don't really want to think about it just for special cases, but being able to use running it under Dask might just speed it up, so that's cool.
 
00:12:53 KENNEDY: Yeah, basically just create a Dask client or something. And it'll locally create a little server cluster that'll process it all. It's pretty cool.
 
00:12:59 OKKEN: Yes.
 
00:13:00 KENNEDY: Or run on a thread pool or something like that. Last thing I thought that was kind of interesting. Maybe do this for me, click on the Dask thing to open it up and just go to the bottom. Notice the 'supported by' there?
 
00:13:11 OKKEN: Wow.
 
00:13:11 KENNEDY: Isn't that cool? Supported by the NSF. Supported by NVIDIA. Supported by DARPA, Anaconda Inc. Things like that. So here's a really interesting example of not just a project that's cool, but an open source project that's like really supported by some neat companies or organizations. So, anyway, I just kind of thought that was a cool thing that jumped out at me as well as kind of the proper support this project's getting.
 
00:13:37 OKKEN: Oh definitely need to check this out. Yeah, neat.
 
00:13:39 KENNEDY: Yeah, pretty cool. It might tie in with graphing.
 
00:13:42 OKKEN: Yeah. Actually there's some pretty graphs on the Dask website. But if you don't want to, I don't know how they're using it, but it's possible to do animations even within Matplotlib.
 
00:13:53 KENNEDY: Nice.
 
00:13:54 OKKEN: And I'm highlighting an article by Parul Pandey. Sorry if I'm getting that name wrong. Called Animations in Matplotlib. I thought we'd already covered this, but we haven't yet. Just the fact that you can do animations. I guess I hadn't realized when I first stated working with plots in Python that Matplotlib did it and you can do some lots of different ways you can simulate or do animations within Matplotlib. And the top picture of the article is this raindrop simulation and I could just sit and watch this for like an hour.
 
00:14:29 KENNEDY: I was thinking the same thing. It's like the equivalent of white noise, but visual. It's just like, yeah, it really does look like raindrops hitting a little pond or a puddle or something. It's quite cool.
 
00:14:40 OKKEN: Right. So it has these random circles that appear dark and as they get bigger they get lighter and then they eventually disappear and that just happens all over the page, and it's pretty neat, but that's all using Matplotlib animations. And there is a certain link to the source code for that, but the tutorial goes through and talks about, there's a couple of different ways to do animations and the author prefers funk animation and has tutorial for animating a sine wave. The confusing part of that to me was that the X axis doesn't really mean anything at that point because the sine wave keeps moving.
 
00:15:16 KENNEDY: Right.
 
00:15:16 OKKEN: But it's a pretty small concise example of how animations work.
 
00:15:20 KENNEDY: Yeah, it's super easy. So basically you create a figure, set it up in Matplotlib, you create an initialize function that sets the data however it's going to be, and then you have an animate function that's given a frame and it just computes the change and you know, sets it again. Yeah, it's quite nice.
 
00:15:35 OKKEN: Yeah, just a few lines of code. She goes on to, I think it's a she, goes on to talk about live updates. So if you've got a graph or a plot that is using data that is changing, and you can live update those animating turning a 3D plot. And that's really pretty,
 
00:15:52 KENNEDY: Yeah, there's a bunch of cool graphs here. I could see if I had stuff to graph, I would be all over this.
 
00:15:57 OKKEN: I guess there's a third party package called celluloid that makes some of the animations a little bit more concise. So she gives some examples of that too.
 
00:16:04 KENNEDY: Cool. Yeah, that's a good one. The last one here for us is PEP 554, multiple interpreters or sub-interpreters in the standard lib.
 
00:16:14 OKKEN: Oh, wow.
 
00:16:15 KENNEDY: So this is kind of metta and interesting and possible. So this I don't believe is approved yet. This is potentially possibly coming. So I don't think it's out. Yeah, proposed in Python 3.9 and we'll have to see if it's, yeah, I don't see whether it's approved or not. But maybe probably in 3.9 coming as this PEP 554, which allows for multiple sub-interpreters in the standard lib. So apparently CPython already had this capability to have multiple sub-interpreters run, but it was never exposed. Right. So deep, deep down there's some module you could use and here's like a public API on top of that. So why do you care about it? Well, it says the proposal introduces the standard lib interpreters module, like import interpreters. And currently it's provisional. And it basically exposes this core functionality as sub-interpreters already provided by the C API along with new functionality. Here's the most important part for sharing data between interpreters. So the idea is you're going to set up some kind of channel, which is like a queue or a named pipe or something like that to pass data back. Like I can't take an object I've created in one part of my program and share it with one of these sub-interpreters. I've got to like JSON serialize it or pickle it and then bring it back or like there's no data sharing, which is really interesting for isolation. So the main use case of this is one running code in isolation. Like if you want to work within your process and you don't want to kick off another process say with multiprocessing or something, you can still run code that you don't necessarily trust with some restrictions here because it won't have access to your memory structures or anything like that. It'll just be like a little isolated Python, but you don't have to result to multiprocessing.
 
00:17:59 OKKEN: Yeah, that's cool.
 
00:18:00 KENNEDY: So that's kind of cool, maybe you plug-in systems or something like that or maybe even incompatible versions of modules. Like maybe, I've run into this with docopt all the time for some reason and like Mailchimp will only use this version, but something else requires another version, like ones less than something and some other has to be greater than that. You know what I mean? So maybe you could run like that part of the code in one of these sub-interpreters and have it run on a different version. I'm not sure. That might take a little bit of juggling, but another one that, the one that stood out to me, and I think it's pretty interesting here, is the GIL, the Global Interpreter Lock is there because you know basically, the way people perceive it as is it blocks parallelism, but the reason it blocks parallelism is around memory management of shared objects, right? So any PyObject you have, it has to have reference counting and whatnot to keep its memory managed. Well, these sub-interpreters don't share objects so they don't share the GIL, which means you could have like true computational parallelism in your code.
 
00:19:02 OKKEN: So they all have like their own GIL?
 
00:19:04 KENNEDY: Effectively, yes.
 
00:19:05 OKKEN: Yeah, okay.
 
00:19:05 KENNEDY: Exactly. So it's still the GIL, but if you have a bunch of them then it doesn't really matter and you don't have the overhead of multiple processes or passing data from multiple processes or all that.
 
00:19:14 OKKEN: The case that I'm thinking about is people that have tried to write their own little IDE or even a big IDE in Python to run Python. There you've got this issue that you still only have one GIL, so you've got to do, launch another thread, you have to have another task or something. And this would allow something like that to be easier.
 
00:19:30 KENNEDY: Yeah. So I don't actually, yeah, I agree. I don't know what actually would come out of this, but it looks like it has some interesting potential and it's also interesting that basically it just formalizes what was already there, so that's pretty cool too. Awesome. Well, that's it for our main topics. You got any extra stuff you want to throw out there?
 
00:19:50 OKKEN: Other than I'm just super excited about PyCon.
 
00:19:52 KENNEDY: Yes, it's PyCon eve. I'm so excited. It's going to be good. I'm looking forward to seeing you and everyone in Cleveland.
 
00:19:58 OKKEN: When are we going to be around. Do you remember our times?
 
00:20:01 KENNEDY: Uh, middle of the day ish.
 
00:20:04 OKKEN: Yeah, ish. After lunch. So come try to find us out there.
 
00:20:07 KENNEDY: Yeah, we won't be at the booth all the time. We're going to be doing other events like open spaces and live recordings and other places and maybe even attend to talk, who knows? The times that we will be there, it should be posted on the booth. So there'll be at least three hours each day that we're doing something interesting there that you can come by and see us.
 
00:20:24 OKKEN: Yep, come get stickers.
 
00:20:25 KENNEDY: Definitely find us a PyCon.
 
00:20:27 OKKEN: How about you? You've got some big news.
 
00:20:29 KENNEDY: Yeah, I got some big news. The big news is my iOS APP is finally out after negotiating, let's call it with the App store folks, who were better than Google Play, but still it was quite the back and forth to get everything right. So finally the Talk Python Training, iOS App is out, check it out at training.talkpython.fm/apps. If you install it, log in, you can get two free courses in addition to the ones you might already have. So that's pretty cool.
 
00:20:56 OKKEN: Yeah, I installed it this morning.
 
00:20:57 KENNEDY: You did? You're already on top of it.
 
00:20:59 OKKEN: Yeah, it looks great.
 
00:21:00 KENNEDY: Right on, thanks. That's very cool. And then lastly, you know like I've said our listeners are awesome. Anytime we say here's something that's kind of unique, they are like, and the five other amazing ones. So here's one called Blessings. We talked about Bullet and we talked about Cooked Input and Blessings is kind of in that realm of making terminal input nicer. And this is also output. It's not exactly the same, but Blessings lets you do things like bold your terminal output and move the cursor around and do all sorts of cool stuff. So this is from Eric Rose and Preston Daniel sends this over and said, "Hey, you should check this out "in addition to the ones you're talking about." So here it is. Looks pretty cool.
 
00:21:37 OKKEN: Oh, I have the exact use case for this in mine, so yeah.
 
00:21:39 KENNEDY: Nice. What are you going to do with it?
 
00:21:41 OKKEN: I want to do like I just got finished with the reading, the TDD By Example. Yeah, I know you would've thought I would've learned that beforehand, but yeah, finally read it. And one of the things is a to do list that is bold for stuff you're working on and like not.
 
00:21:58 KENNEDY: Nice, yeah.
 
00:21:58 OKKEN: And anyway uses that so typical.
 
00:22:00 KENNEDY: Yeah, there it is. Awesome. All right, we have a joke coming in from Topher Chung. Do you want to do it or I do it?
 
00:22:06 OKKEN: Oh, you do it.
 
00:22:07 KENNEDY: All right. Knock knock race condition.
 
00:22:09 OKKEN: Who's there?
 
00:22:14 KENNEDY: Wait Mike race condition, who's there? Oh, all right, well.
 
00:22:17 OKKEN: It's never get old. We can do ...
 
00:22:20 KENNEDY: I am starting to notice that the pyjoke well is starting to run a little dry. We've been emptying it a lot. So people we have to start sending in their jokes. That was a good one. Thank you, Topher.
 
00:22:30 OKKEN: Yeah, thanks.
 
00:22:31 KENNEDY: All right, well Brian and we shall reconvene in Cleveland.
 
00:22:34 OKKEN: Yeah, talk to you there.
 
00:22:35 KENNEDY: All right, see you, everyone there. See you Brian. Thank you for listening to Python Bytes. Follow the show on Twitter via @pythonbytes. That's Python Bytes as in B-Y-T-E-S and get the full show notes at pythonbytes.fm. If you have a news item, you want featured just visit pythonbytes.fm and send it our way. We're always on the lookout for sharing something cool. On behalf of myself and Brian Okken, this is Michael Kennedy. Thank you for listening and sharing this podcast with your friends and colleagues.
 
