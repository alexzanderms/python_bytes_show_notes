00:00:00 Hello and welcome to Python bytes where we deliver Python news and headlines directly to your earbuds. This is Episode 185. Recorded June 4 2020. I'm Michael Kennedy. And I am Brian. Okay, and this episode is brought to you by data dog. More on that later. Check them out at Python bytes. FM slash data dog. Brian, I feel like we're all working from home. everyone's life is scrambled even like my sleep schedules are scrambled like some crazy stuff happened. And I slept from like six to 930. And I was up for like, four hours and I slept in like it's just, it's weird. Don't we need more structure in our life? Next nice interest. Yes, your structure. Yeah. I'm a fan of markdown. Also, believe it Trust me. It's not a tangent, though we have a just a repo that we want to point people to called missed. It's got to be called missed, I think, Oh, yeah. Definitely, NYS t which is markedly structured to text. And what this is, is a fully functional markdown parser. For Sphinx, it's markdown, plus a whole bunch of stuff from restructured test, restructured to text. So mist allows you to write Sphinx documentation entirely in markdown, and things that you could do in restructured text, but could not do in markdown have been put in a there's a new flavor of markdown. So you can do all of your directives, and all sorts of cool things like anything you could do in restructured text with Sphinx, you can now do in markdown, it's based on common mark and some other tools. So they're standing on other tools that are already doing things really well. And just extending them a bit. But this is pretty powerful. One of the things I like about this is I particularly don't use a lot of of Sphinx, but this also includes a standalone parser. So you can to somebody extended markdown for these extra directives, and even use some of them in your own code if you want. So yeah, this looks really, really nice, like restructured text is good in all, but I don't know, if I'm gonna write something like restructured text, my heart just wants to write markdown, I gotta tell you, Yeah, me too. And the I think one of the things that was holding a lot of people back is some of the extra directives that like information boxes and other things like that, that you you can't necessarily do in markdown off the shelf. But some extensions are nice, I played with a little bit doing some just, I didn't pull it down with Sphinx, I just pulled it down so that I could run some markdown through it and some of the extra directives to see what it has. So for instance, some of the directives like I tried like an information box, you can have structure around putting an information box somewhere. And what you end up with is a div that has a class to it. Oh, nice. If you're not using Sphinx, then you'll have to use your own CSS, I guess to style it, but it puts in enough hooks for you to be able to do that. That's really nice. I do wish you could sort of indicate CSS styles and markdown because Wow, that would just that would be the end of what you need. html for for many, many things. That would be nice. So last week, you brought up dirt Earth, we were talking about? How do you store your secrets? How do you activate and configure different environments? I think I even said something about like, specifying where Python was running. I don't remember what the context was exactly. But you're like Durham, and actually I've been meaning to cover this, Dunder Dan, like them on Twitter. I don't know his last name is Thanks, Dan, sent this over to us as a recommendation. And I'm like, Yeah, like you brought it up, it seems definitely cool. So let me tell you about dir, and dir, E and V. So it's an extension that goes into your shell. And normally, what you do is you open your shell and it runs your bash, RC, xe, HRC, whatever, and sets up some stuff. Or if you're ever on Windows, or a little bit different, but I think dirt is only for the POSIX type systems. Anyway, it'll set up some values that you put in there, like environment, variables, and whatnot. And that's just global, right? You can also set up when you activate a virtual environment to export other values. That's pretty cool. But what it doesn't really do is allow you to have like a hierarchy of values. So if I'm in this subdirectory, over here, I want this version of Python active, or this version of where the flask app lives. And then if I change to another directory, I want it to automatically go well, that means different values. And dirt. Envy basically, does that. Oh, nice. Yeah. So as you go into different parts of your folder system, it'll look for certain files.nv RC and if it finds that, it will automatically grab all the basically all these exports and then jam them into whatever your shell is. And it's also cool because it's not a shell, right? It's not like Well, here's a shell that has this cool feature. It works with bash z shell TC

00:05:00 shell fish, and another's. Right? So it's basically a hook that gets installed for like I use, oh, my z shell, because oh my gosh, it's awesome. And then I would just plug this into it. And as I do stuff with z shell, it will just apply its magic. Yeah. And so one of the things that one of the things you can do with this is to automatically set a virtual environment. If you go into special directories. That's not the only thing it can do. But that's one of the reasons why a lot of people use it, right, basically, well, I guess you can't do aliases, you can't change what Python means. But you can say where the Python path is. Yeah, that's one of the things that's a limitation of this that people should be aware of is it doesn't, the way to think of it is not as a sub RC, right? It's not a sub bash RC where like it runs, aliases, and all sorts of stuff. The way it works is it runs a bash shell like a little tiny hidden bash shell. It imports that as the bash RC it captures what the exported variables are throws away that shell and then jams that into whatever active shell you have, like z shell, or bash or fish or whatever. Yeah, I would probably use this all the time if I weren't, wasn't somebody that used both Windows and Mac, and Linux frequently. So you'll probably I bet somebody could come up with this thing for Windows as well. It's just got to be like totally from scratch, different type of thing, right? People have already pointed me to, to Windows versions of it. But it's those things of like, you got to jump through hoops to make it work. And it's just not something for me, it's not solving a big enough problem that I have that I need to jump through the hoops. But I agree. I agree it is cool. But it doesn't. It's not like life changing in that regard. I guess one more thing to point out is it's you don't have to like go to the directory where the environment RC file is, it looks up the parent directories until it finds one. So you have this like hierarchy like I'm down here in the you know, like, views part of my website and the top level of that Git repo, I have one of these NVR sees it would find that in like activate that for you. So that's pretty cool that it has it's kind of like Node JS, where the node modules live in that regard. That's pretty cool. Yeah, that's a really nice feature. Yeah, for sure. Also, nice data dog. So before we get to the next thing, let me talk about them real quick. They're supporting the show. So thank you, they've been sponsors for a long time, please check them out, see what they're offering. It's good software, and it helps support the show. If you're having trouble visualizing bottlenecks and latency in your app, and you're not sure where the issues are coming from or how to solve it. You can use data dogs end to end monitoring platform, with their customizable built in dashboards to collect metrics and visualize app performance in real time. They automatically correlate logs and traces at the individual level of requests, allowing you to troubleshoot your apps and track requests across tiers. Plus, their service map automatically plots the flow of these requests across your application architecture so you can understand dependencies and proactively monitor performance of your apps to be the hero that got that app at your company back on track. Get started with a free trial at Python bytes at FM slash data dog. You can get a cool shirt. All right, right. What's next? Yep. Thanks, David. I had a problem. So my problem was a little application that had a database. It was a I was using tiny dB, just for development. You could use Mongo similar. It's a document database, throwing some data into it, no problems. But I, that was one of the values that I decided to change to use Python genomes, because I thought enums are cool. I don't use them very often. I'll give these a shot because they seem like perfect. And then everything blew up, because I can't couldn't save it to the database. Because enums are not serializable by default. So I'm like, there's got to be an easy workaround for this. And I first ran around ran into questions about or topics about creating your own serializer. That just didn't seem like something I wanted to do. You could do it, but it's not so fun, right? Yeah, well, so I ran across an article, a little short article written by Alexander Hoeppner called converted Python named Jason. And I didn't need it converted to Jason but I did need it serializable. And the trick is to just if you're doing your when you're using them to you do from a new moon port, the capital II new type, and then you have a class that derives from that. And then you have your values. Well, if you also derive from not just noon, but another salt concrete type, like like int or string, and in my case, it was using a used string so that my string values would be stored. Now it is serializable. And it works just the same as it always did before. It's just uses the serializer from the other type. And it just works incredible. So for instance, I'm going to put a little example in the show notes about using a color, which is red and blue. And if you just use drive for medium, you can't convert it to Jason because it's not serializable you can either do an NT named

00:10:00 Which is a built in one, or combine stir and you know, now it serializes just to the string red and blue if that's the values, and then that's what's stored in your, like your database too. So, when I'm using, it's really handy for debugging to be able to have these these readable values as well. Yeah, this is really cool. It's a little bit like abstract base classes versus concrete classes or something like that, right? You've like the General innum. But if you do the NT neum, then it has this other capability, which is cool. Yeah, multiple inheritance, stir comment, you know, is the one you went for, right? Yeah. So the multiple inheritance is the thing that Alexander recommended in his post, that's what I'm using and works just fine. But I was interested to find out that in the Python documentation for Inti noon at noon was almost just there as an example to say, we realized that it might not be integers that you want, you might want something else. But there's an example right in the in the Python documentation on on using multiple inheritance to create your own type. It doesn't talk about serializability. There, but that's one of the benefits. Yeah, it seems like it works. Anyway. Awesome. Yeah. How much time did it take you to figure that out? was a long time? No, I don't know. 10 minutes a Google? Yeah, it's pretty cool. Well, you could compute it with Python, of course. But you know, the daytimes in Python and timespans. are, they're pretty good, actually. But they're a little bit lacking. They're certain types of things you might want to do with them. And so there's a couple of replacement libraries, and one that Tucker Beck sent over called pendulum. That's pretty cool. Have you played with pendulum I haven't. But I like the name. Now I do, too. It's really good. I've played with arrow. So this is a little bit like arrow, but it doesn't seem like it tries to solve exactly the same problem that just like let's make Python date times, and time delta is better, which is kind of the goal of both of them. So it's more or less a drop in replacement for standard date time. So you can create, like time deltas, which are pretty cool. Like I could say pendulum duration, days equals 15, I have this duration, it has more properties than the standard date, time or the time delta, you get like total seconds or something like that. But that's, you know, that's not that helpful. So this one has like duration, dot weeks duration, dot hours, and so on, which is pretty cool. You can ask for the duration in hours, like the total number of hours, not just the number of hour, you know, like three hours in two days, or whatever. But you also have this cool, like, human friendly version. So I can say duration, in words, and give it a locale and say like, locale is US English. And it'll say that's two weeks in one day. Nice. You can also like, let's suppose I'm trying to do some work with like calendars, or some kind of difference. I say, the time from here to there. I want to do something for every weekday that appears right? So skip Saturday and Sunday. But if it's like from Thursday to Wednesday, I need to go Thursday, Friday, Monday, Tuesday, Wednesday, yeah. So I could say pendulum dot now. And then I could go from that and subtract three days. So that would be a period of three days. And that gives you what they call a period, which is a little bit different. And then I can go to and say, convert yourself to in weekdays. Okay. Right. not interesting, then you can loop over it, you can say for each day, or each time period in this period and go it would go you know, over the weekdays that are involved in that timespan. That's pretty cool. Yeah. Cuz that would not be so much fun to do yourself. There's a bunch of stuff that he does, and I don't want to go like read all the capabilities or whatever. But that gives you a sense, like if these are the kinds of problems you're trying to work through. And you're like, Man, this is a challenge to do with, with the built in one. Check out pendulum also checkout arrow. I think we've covered arrow A long time ago, if we haven't Well, I'll cover it at some point. It's a good one. Yeah. And I think actually, I don't think it's a matter of which one's the best either. It's a it's whatever seems to speak to you. And as an API that thinks like you do. Yeah, it's good that lots of people have sold things like this. Yep. Absolutely. All right. Well, what's this next one? I'm trying to be like a private detective or what's going on with it?

00:14:02 Yeah, a private detective looking into and spying on your code. So this was sent off by a Twitter account called piling. And this is pi Snooper. The claim is never used print for debugging again. And I have to admit, I'm one to lean on the print statement every once in a while, especially if I'm just sometimes I don't really want to do use breakpoint, because I, I've got some code that's getting hit a lot. And I really do want to see what it looks like over time. So one of the things that people often do is throw a print statement somewhere in a line just to say, Hey, I'm here. The other thing they do is like print out a variable name right after an assignment so that they can see when it changes, but that's exactly what this and now it's that. Yeah, so this is exactly kind of what it does. So by default, it's just a, you can throw a decorator on to a function, and that's the easiest way to apply it. For pi Snooper decorate a function and now

00:15:00 Every time that function gets run, you get a play by play log of your function. And what it logs is it logs the parameters that gets passed to your function, it logs all the the output of your function, but also every line of the code of the function that gets run. And every time a variable is changed, changes its value. And then even at the end, it tells you the elapsed time for the function. So that's quite a bit, if that's great for you great, but if it's too much information, you can also isolate it with a width block and just take a section of your function under test and just log a subset. And then if local valuable local variables are not enough, and you you're changing some global variable, you can tell it to watch that as well. Anyway, it's a pretty simple API. And there's actually quite a few times I think, probably reach for this when I first saw this, I'm like, Yeah, yeah, it's kind of cool. There's a lot of these replacements where I think like, you know what, you've got pi charm, or you've got VS code, you're better off just setting a breakpoint. And the tooling is so much better than like, say, PDB, or something like that, right? Yeah, this though, this solves a problem that always frustrates me when I'm doing debugging, which is, you're going around, you've got to keep a track in your mind. Okay, this value was that now it's this and then it became that and like, sort of the flow of data, like at any frozen point, you can see really well with the visual debuggers, right, like pie chart or whatnot, what the state is, you can see even what's changed, but like this number, when this list was empty, empty, then this was added, then this was added. And here's how it evolved over time, people should check out the readme for this because that view of it is like there's a loop where it shows going through the loop four times and as like all the values and variables like build up, so you can just like review it and see how it flows. I think it's pretty sweet. Actually. Yeah, one of the other things I forgot to mention is, is if you're like debugging a process on a server, maybe it's a, you've got a Yeah, small service that it's running. And instead of standard out, you can pipe these logs to a file, and, you know, review them later. Yeah, for definitely for a server as well would be nice to flip that on. And I guess with the with the conditional, but you could probably even in code, say do you feel like you're running into trouble, turn on the PI, Snooper for a minute, and then turn it out? You know, like, there's, there's probably options there. But yeah, you definitely wouldn't want to attach a real debugger to like, production.

00:17:23 Dude, why wasn't the site work? Oh, somebody's got to go back to their desk and hit F, you know, f5 or continue or

00:17:30 whatever, it's not gonna go well. So I have something that's pretty similar to follow this up with that, you know, this is about debugging and seeing how your code is running. Like, per usual. We talked about one tool, and people are like, Oh, yeah, but did you know about? So we've talked about Austin, and we've talked about some of the other cool debugger profilers. And so, over on pi coders, they talked about fill F I L, which is a new memory profiler for data scientists and well, General scientists. And you might wonder, like, why did data scientists read, you know, biologists? Why can't they just use our memory profile? Like, why is Austin not their thing? Right? And it may or may not be like, it may answer some great questions for them. Like, obviously, they do a lot of computational stuff, making that go much faster, faster. Let them ask more questions. Right? So maybe profilers, in general, are like things they should pay attention to. But you know, when they talk about this, they say, look, there's a really big difference between servers and like data pipeline or sort of imperative, just top to bottom code. We're just going to run scripts, sort of all right. And that's what scientists and data scientists do a lot. So like, I just need to do this computation and get the answer to servers. If you're worried about memory, remember this a memory profiler? What you're worried mostly about is, you know, this has been running for three hours. Now, this servers out of memory. That's a problem, right? Like, it's, it's probably an issue of a memory leak somewhere, something is hanging on to a reference that it shouldn't. It like builds up over time, like cruft and it just eventually wears it down. And it's just like, bloated, you know, with too much memory, right. So that's the server problem. And I think that's what a lot of the tooling is built for. But data pipelines they go, and they just run top to bottom. And they don't, for the most part, don't really care about memory leaks, because they're only going to run for 10 seconds. But what they need to know is if I'm using too much memory, what line of code allocated that memory? Like, I need to know what line where I'm using too much memory? And how can I like maybe use a generator instead of a function in a list, or something like that? Right. So that's what the focus of this tool is, is it's like, it's gonna show you exactly what your peak memory usage is, and what line of code is responsible for it? This is actually pretty cool. It is right? What is this? Like? Why do they need their own thing but as I've looked at, they're like, this is actually pretty cool.

00:20:00 Then, if you go to the site, you can actually see they give you this graph, like a nice visualization of I cured the lines of code. And then it's like more red or less red, depending on how much memory it's allocated. Oh, yeah. And then the total amount and you can like dive into like, Okay, well, I need to see like this loop or this sub function that I'm calling. How much is it? So you can like navigate through this visual, like red pink gray of like, memory badness? I guess. I don't know, memory usage? Yeah, that's not bad, right? No, yeah. And when you're staring at code, it's obvious where the huge array might get generated or used. Yeah. And the example they have here, it's like, Okay, well, they have a function called make big array. Okay. So like, probably, that's why it Look there. And there's also things like, like using NumPy, like, okay, here, we're creating a bunch of stuff with NumPy. And you might say, Well, here's the NumPy thing that we're doing, that makes too much, but you could be doing like a whole bunch of, you know, NumPy and pandas work and like one line is actually responsible, but you're probably pretty sure it has to do with pandas, but you're not sure where exactly right. So you could you know, dig into it. And see, I think it's cool. Yeah, we thought we were using arrays. And suddenly we have this huge matrix that accidentally. Exactly why is all this stuff still in here? Yeah, cool. Well, anyway, if you're doing data science, and you care about memory pressure, this thing seems super easy. It even has like a tried on your own code on the website, which I don't know what that means. But that's crazy.

00:21:24 Not uploading my code there, but it's fine. All right. Well, Brian, that's it for our main items. You got anything? I don't. I've just been trying to get through the day lately. Yeah, I hear you. Well, I've one really quick announcement, and then an announcement, in a sense. So I sent out a message to a ton of people. So announcement is for them. So what I'm trying to do is I'm trying to create some communities for students going through the courses to go through them together. And I'm calling these cohorts, right, so I set up like a beginner Python cohort, in a web Python cohort. And put like 2030 people, I had 2030 slots, let's say for people to go through over like three or four, three months or so where they each work a little like, they all work on the same part of the course at the same time. And they're there to help each other. There's like private slack channels and other stuff around it. So that's really fun. But it turns out that after one day of having that open, I got many hundreds of applicants for, like 20 spots. So I had to stop taking applications. So if people got those messages, and like I want to apply, but it looks like the forum is down, it's because there's like an insane number of applicants per spot. So those will come back. And people can sign up to get notified. There's a link in the show notes. But I just want to say like, that's what I was doing, which is fun. But for those of you who didn't get a chance to apply, because it got closed right away. That's why and that's for training it. Talk Python. FM. Yes, exactly. So there's like, certain courses and if you got one of the courses and you want to go through it with a group of students, all on the same schedule. This was like a free thing that I was doing to try that out. Yeah, right. Think it's a neat idea. Yeah, thanks. Yeah, people seem to like it. Yeah, me too many. But uh, yeah, gotta gotta give it a try. Get it dialed in that we can open up some more groups. Yeah. All right. Well, I've got it. I've got a joke. I kind of like for you here. I love this one. Are you ready for it? Yeah, you want to be? Why don't I be the junior Dev, you can be the senior Dev. So the junior Dev and senior dev are having a chat. And I feel like that you may be a little skeptical of what I've done here. Let's just do this. I want you get hit me with a question. Okay. So where did you get the code that does this? Where did you get the code from? Oh, I got it from Stack Overflow. Was it from the question part or the answer part?

00:23:39 Isn't that so good? It's like, people think coffee for StackOverflow is bad. I think this question.

00:23:47 From the question part. Yeah, actually, I've never heard anybody like, you know, spell that out. You know, you know, I don't look up stuff on StackOverflow. But at the top with the question, don't copy that. That's the code that somebody's saying. This doesn't work. Yeah.

00:24:02 Exactly. Exactly. That's funny.

00:24:05 This is a good one.

00:24:08 Too funny. It's too funny. All right. Well, thanks. As always great to chat with you and share these things with everyone. Thank you. Follow the show on Twitter via at Python bytes events, Python bytes as in VYT s and get the full show notes at python bytes.fm. If you have a news item you want featured just visit Python by set FM and send it our way. We're always on the lookout for sharing something cool. On behalf of myself and Brian knockin. This is Michael Kennedy. Thank you for listening and sharing this podcast with your friends and colleagues.

