00:00:00 Hello, and welcome to Python bytes where we deliver Python news and headlines directly to your ear buds. This is Episode 197. Recorded August 26 2020. Brian, can you believe it's the end of August? Even if I can't say it, it still is true. No, I can't I don't know where August went. It just thought this whole pandemic thing would make the summer seem long and slow. It seems like it just went faster. Yeah, I've got like a Lego kit that I was planning on doing like the first week week of summer vacation, and it's still sitting there. So yeah, for sure. Any Yeah, there's a lot of things I want to get done before the sun goes away and rain starts for six months straight. That's in Pacific Northwest problem, but it's our problem. All right. Now this episode is brought to you by us as well, we'll tell you more about the things that we're doing that we think you will appreciate later. Right now I want to talk about something that I think we might have covered before. But I don't know if we've ever satisfactorily covered it. Maybe this time, we'll get closer. And that's async IO. Oh, yeah, I think that's a new topic. It's totally new topic, covered only less than gooeys. Now. So there's a new Ouch, I put a new compatibility like layer library that allows you to work a little bit better with async. io and some of the other async libraries that are not directly meetly. The same as are built right on top of async IO Curio from David Beasley and trio from thin you'll Smith. So there's an article that talks about this I'm going to mention as part of this conversation, then say, hey, Python three well known concurrency libraries built around async and await syntax async. I O Curio and trio. True, but where's unsynced? People unsink is the best of all four of those. I don't know where anything is. Anyway. unsink is not part of this conversation. But unsink plays a role a little bit like this thing I'm going to talk mentioned today is any IO.

00:01:56 And it's pretty clever name because the idea is that it provides structured concurrency primitives built on top of async IO. Okay, right. So one of the challenges with async IO is you can kick off a bunch of tasks, and then not wait for them and your program can exit or you can do other things. And you maybe you've seen runtime warnings like tasks such and such was never awaited, you're like, Huh, I wonder what that means? Well, that probably means your program exited while it was halfway done, or something like that right? Or your thing or turn the value before it waited for it to finish right. And at the low level, something that's a little bit frustrating or annoying that you got to deal with is that you've got to make sure that all the stuff you started on the async event loop that you wait for that event loop to finish before your program completely shuts down or completely carries on. And so that's basically the idea of this libraries. It's, it's a compatibility layer across those three types, the three different well known concurrency libraries that provides this structured concurrency. So if you look at Wikipedia, they say structured concurrency is a programming paradigm aimed at improving the clarity, quality and development time of a computer program by using a structured approach to concurrent programming. The core concept is encapsulations of threads of execution, by way of control flow constructs that have a clear entry and exit points. In Python, this mostly manifests itself through this library as async, with blocks or async, context managers. They're like, I'm gonna do some async work. So let's create a width block, do all the work in there. And then by the way, when you leave the with block, it's going to have made sure all the tasks that were started in the task started by those tasks and so on, all finished. Oh, that's nice. Yeah, that's pretty cool. So the way it works is you basically go any IO create task group, and then from the task group, you can spawn

00:03:52 other sub tasks, and it, it will keep track of those, if there's an exception, I believe it will cancel the other undone one to unfinished ones, and so on. So it's about, say, we're just gonna go through this thing, and it's all gonna run here. And like it enters at the top, and it exits at the bottom of the width block. Okay, that's pretty cool, right? Yeah, yeah. So I think that that's pretty neat. So as other primitives, so that's like a real simple example. Other example or other things, it does include synchronization primitives, locks. So

00:04:22 if you create a reentrant lock in Python, often called a critical section and things like c++ and whatnot, it's never ever going to help you, well, maybe that's a little bit strong, it's likely not going to help you. Because those mechanisms come from the operating system process level. And what they do is they make sure two threads don't run at the same time. Well, with async IO, it's all a bunch of stuff that's being broken apart on a single thread, right, it's all on the one wherever the the event loop dot run is run to complete or whatever. Wherever that's happening. That's the thread so like the thread locks don't matter. It's all the same thread, like you're not going to block it.

00:05:00 Anything. So having primitives that will kind of function like threads to protect data, while stuff is happening, while it's in temporarily invalid states, that's pretty cool for async IO. Okay? So you need it, or you donate it, you probably need it, I think people often don't really think too much about these invalid states or programs get into and you think, well, async IO, it's gonna be fine. And a lot of times, what you're doing with async IO is kind of standalone, like, I'm going to kick off this thing. And when it comes back, I'm going to take the data and do something. But if you're modifying shared data structures, you could still end up in some kind of event loop, a race condition, it's not as bad as like true threading, because you're not going to it's I don't believe it's like a plus equals, I have something that actually might be multiple steps at the lower level runtime, I don't think that it will get broken up to that fine grained. But if you say like, debit this account, this amount of money, a weight, debit this account, this amount of money, a wait, put that amount into the other one. And some other one is like reading in some kind of loop like that level of higher order, like temporarily invalid state, that could be a problem for async. io, and you want some kind of lock. So this comes with that it comes with streams, which are similar to queues timeouts through things like move on after or fail after a certain amount of time, and so on. So it's pretty cool little library. Yes, thanks. My vote still for unsink is the best of the four, even though as I mentioned,

00:06:26 isn't unsync built on those? So it's a compatibility layer that takes async IO, threading and multi processing and turns them all into things that you can await? Oh, yeah. Yeah. So don't you think there should be like a standard like, they should get together like some consortium and have a standard about this? Yeah, well, they probably should. But we're still in the early stages of figuring out what the right API is better. That's why they haven't done it, there's something else that has that could use some standards. And that's in a lot of days, data science libraries. There's an announcement that there's a new Consortium for Python Data API standards. So there is one happening and it's happening actually quite fast. They're getting started right away. And there's activities, to the announcements right away, then in September, I believe they're gonna kick off some work on dataframes are on know, starting with arrays, and then move on to data frames. And so okay, I'm getting ahead of myself. There, a little blurb says, one of the unintended consequences of the advances in multiple frameworks for data science, machine learning, deep learning and numerical computing, is that there is fragmentation. And in using the tools, and there are differences in common function signatures, they have one example, that shows what the generally mean function to get the average or mean, given we're going to, like flame me for calling average mean. But as a commoner, I kind of think of those the same thing. But anyway, they show a different frameworks then. And some of them are common with other ones. And so there's five different interfaces for over the eight frameworks for just the mean function for an array. Yeah. And what's crazy is like, they all are basically the same. They're so so similar, but they're not the same, not code wise, the same, but they might as well be. Yeah. And so one of the issues is there's people are using more than one framework for different parts of their maybe different parts of their data flow. And sometimes you can kind of forget which one you're using, and having a lot of these things common, actually would just make life easier. I think. So I think I don't know how far they'll get with this. But I think it's a really, so they're trying to make all of these, these frameworks look exactly the same. But with commonalities in arrays and data frames, or, and this note that arrays are also called tensors. So those are trying to make some of those common is, I think, a really good idea for some of the easy simple stuff. Why not? It seems like a great idea. It seems like a huge challenge, though, like, Who's gonna give whose function is going to be the one that's like, yeah, we're dropping this part of our API to make it look like everyone else's. Right. And that's why I think that they've went through a lot of thought on how to go about with this process and try to convince people so they're working with, they're trying to kind of be in between the framework authors and maintainers. And the community and try to do some, some review process for different API's put a proposal out, have feedback from both from from the different projects, and from the community to have have more of a, you know, more input to try to make it It isn't just like one set of people saying, Hey, I think this should be this way. Yeah, it's a good idea. It would be great if a lot of these application or these frameworks, maybe renamed if it's the same function, if it's like, for instance, mean in this example, if it's spelled exactly the same, maybe it should be

00:10:00 The same API. And if you want a special version of it, maybe ever have a underscore with an extra, you know, some reason why it's different, you can have extra have different functions. Yeah, it seems like you can find some pretty good common ground here. It's a good idea. And if they make it happen, you know, it just be easier to mix and match frameworks in use the best or different situations, because I can certainly see, like, I'm working with pandas here, it would be great if I could do this on CUDA cores with q pi. But I don't really know that it's close, but it's not the same. So I'm just gonna keep struggling here, as opposed to change the import statement. Now it runs there. Yep. I don't know, if it's ever really gonna be like, you can just swap out a different framework, but for some of the common stuff would really be great. And that's why one of the reasons why we're bringing it up is so that people can get on board and start being part of this review process. If they care about it. Yeah. So it seems like there might be some room for like adaptive layers, like from kukai, import pandas layer or something like that, where it basically you talk to the in terms of, say, a panda's API, and it converts it to its internal. It's like, Oh, these, these arguments are switched in order, or this keyword is named differently or whatever. And there's even things like differences in even if the API looks the same, or very similar. The default might be like, in some cases, the default might be none versus false, or versus no value or thing. I don't know what no value means. But anyway.

00:11:26 Yeah. Cool. That's a good one. Now, how's it good is the things that we're working on, Brian, you want to tell folks about our Patreon, actually, we've kind of silently announced it a while ago, but we got 47 patrons now, and it's set up for monthly contribution. And we everything, really appreciate people helping out because there are some expenses with the show. So that's a really cool, we'd love to see that grow. I bet. We'd also like to hear from people about how we'd like to come up with some special thank you benefits for patrons. And so I like to have ideas come from the community. If you can come up with some ideas, we will think about it. And I'm trying to figure out how to get to it. So on our Python bytes, if you're on any episode page, it's there on the right. Okay, if you go to an episode page, got it. Yep. And it says on the right, I believe somewhere, it says sponsors on off the double check, I believe it does. Okay, we'll double check it can for sure. It doesn't already.

00:12:26 And also, I want to just tell folks about a couple of things going on over top Python training, we're doing a webcast on helping people move from using Excel for all their data analysis to pandas, basically moving from Excel to the Python data science stack, which has all sorts of cool benefits and really neat things you can do there. So Chris Moffat is gonna come on reading, of course with us, and he's gonna do a webcast, which I announced it like, well, 15 hours ago, and already has, like, 600 people signed up for it. So it's free, people can just come sign up, it happens late September, Ember 29th, I'll put the link at the extra section of the show notes so people can find it there. And also, the Python memory manager course is out for early access, a bunch of people are signing up and enjoyed it. So if you want to get to it soon, get to it early, people can check that out as well. Very exciting. So this next one I want to talk about has to do with manners. What kind of developer are you? Are you a polite developer, you're talking to the framework? Are you always checking in with it to see how it feels what you're allowed to do? Are you kind of a rebel, you just gonna do what you like. But every now that you can get smacked down by the framework with an exception, I don't work describe how a developer I am, because I don't want the explicit tag on this episode.

00:13:40 So there's an article that talks about something I think, is pretty fun, and interesting to consider. And it talks about the two types of error handling patterns or mechanisms that you might use when you're writing code. And Python naturally leans towards one. But there might be times you don't want to use it. And that is it's the two patterns are it's easier to ask for forgiveness than permission. That's one and the other one is look before you leap, or please, may I All right. And with the look before you leap, it's a lot. A lot of checks, like something you might do in C code. So you would say, I'm going to create a file. Oh, does the folder exist? If the folder doesn't exist, I'm going to need to create the folder and then I can put the file there. Do I have permission to write the file? Yes. Okay, then I'll go ahead and write the file, right? You're always checking if I can do this, if this is in the right state and so on. That's the look before you leap style. The ask for forgiveness style is just try with open this thing. Oh, that didn't work. Catch exception, right, except some IO error or something like that. So there's reasons you might want to use both Python leans or nudges you towards the ask for forgiveness. Try accept

00:15:00 version. The reason is, let's say you're opening a file and it's a JSON file, you might check first, does the file exist? Yes. Do I permission to read it? Yes. Okay, open the file. Well, guess what? What if the files malformed and you try to feed it over to like JSON load? And give it the file pointer? It's not gonna say sorry, it's malformed. It's gonna raise an exception. I can return like a value like malformed constant, weird thing. It's just gonna throw an exception and say, you know, invalid thing on line seven or whatever, right? Yeah. So what that means is, even if you want it to do the look, before you leap, you probably can't test everything. And you're going to end up in a situation where you're still going to have to have the try except block anyway. So maybe you should just always do that. Right? Maybe you should just go up, we're gonna have to have Exception Handling anyway. That's just we're gonna do Exception Handling as much as possible and not do these tests. So that's the this article over here. It's on Swift. watsky.com.

00:16:00 Oh, yeah, it sounds fashion would widow ASCII? So yeah, it's his.

00:16:05 I didn't realize that it was his article. So it's his article. Anyway, he talks about like, what is the relative performance of these things? and tries to talk about it from a Well, sure, it's cool to think of how it looks in code, but is one faster, or one slower than the other? Okay. And this actually came up on talk Python, as well. And so I said, Look, if we're going to come up with an example, let's have a class and a base class. And let's have the base class define an attribute. And sometimes let's try to access the attribute. And when you don't have the base class, or when you only have the base class, it'll crash, right? Because it's in the derived class. So let's say we have two ways to test we can either ask, Does it have the attribute, and then try to access it. Or we could just righto access it. And it says, Well look, if it, if it works all the time, you're not actually getting errors, and you're doing this, it's 30% slower to do the look before you leap because you're doing an extra test. And basically, the try except block is more or less free. Like it doesn't cost anything, if there's not actually an error. But if you turn it around, you say, No, it's not there, all of a sudden, it turns out the Ask the try except block is four times slower. That's a lot slower, really, because the raising of the exception figuring out this call stack, all that kind of stuff is expensive. So instead of just going does it have the attribute going, well, let's do the whole call stack thing, every error, right and create an object and throw it and all that kind of stuff goes a lot slower when there are errors. And anyway, it's a an interesting thing to consider if you care about performance. And things like parsing integers or parsing data that might sometimes fail might not, you know, sometimes it doesn't fail. Yeah. Okay. devil's advocate here, is example, doesn't have any activity in the ask for forgiveness. If it isn't there. That's what the way I felt when I first started as well. There's two sections, there's like one part where he says, let's do it with the attribute on the drive class. And let's do it again, a second time by taking away the attribute and seeing what it's like, right. But I mean, the code that if it doesn't exist, it just doesn't do anything. Right. We're right. Right. In reality, you're still gonna have to do something for the user. Right? Yeah, whatever. Yeah. Okay. Yeah, for sure. That's a good point. Like, it's just basically a try except pass. Yeah. So what do you think about this? So

00:18:29 what I think is, you're gonna have to write the try except, anyway, almost all the time.

00:18:36 And you don't want both? Like, that doesn't seem good. That seems like just extra complexity. So when it makes sense, just go with ask for forgiveness, just embrace exceptions, right? Remember, you have a finally block that often can like get rid of a test as well. You have multiple types of error, except clauses are based on error type. I think people should do a lot with that. That said, if your goal is to like pars specific data, right, like, I'm going to read this number I got off by off of the internet by web scraping, and there's a million records here, I'm going to parse it, if you want to do that a lot faster. That might make a lot of sense. I actually have a just example, that I put up trying to compare the speed of these things in a mixed case. So like, the cases we're looking at here are kind of strange, because it's like, well, there's, it's all errors or zero errors, right? Which and then it doesn't really do anything, which are both weird. But I have this one where it comes up with like a million records, strings, and most the time they're numb. They're legitimate numbers like 4.2 as a string, and then you can parse it. And what I found was, if you have more than 4% errors, it's for like, 4.5% or something errors. Aaron has data, it's slower. To use exceptions. The cutoff is 4% errors. And I think if you have more than 4% errors, then the exceptions become more expensive. That's right. Anyway,

00:20:00 It's something that people can run and get real numbers out of and play with it in a slightly more concrete way. But if I didn't know, what do you think I think you start out by focusing on the code making easy and clear to understand and then worry about this stuff. Yeah. So I don't actually put either I don't usually do the aspirin, or the checking stuff. And that is, one of the things that's good about bringing this up is that is more common in Python code is to not check stuff just to, you know, to just go and do it. And then I write a lot of tests. So I write it to a lot of tests around things. Yeah. So either case checking for things or, like, for instance, if it is if it is input, if I've got user input, I'm checking for things. Yeah, I'm gonna do checks ahead of time, because I want because the behavior of what happens when it isn't there, or when there's a problem, it isn't really a problem, it needs to be designed in the system as to what behavior to do when something unexpected happens. But the in normal code, like, what happens if there's not an attribute? Well, you shouldn't be in that situation, right? You shouldn't be in that situation, I usually push it up higher. I don't have to accept blocks all over the place. I have them around, API's that might not be trustworthy, or around. external systems are something that don't put try except blocks or code that I'm calling them my own code, things like that. Yeah, I'm working on that. That makes a lot of sense. The one time that I'll do the test, the look, before you leave style is if I think I can fix it, right? Does this directory not exist? I'm going to write a file to Well, I'm just going to make the directory, then I'm going to write to it, you know, those kinds of tasks can get you out of trouble. But if you're just going to say this didn't work, chances are you know, you still need the error handling and exception format anyway. Yeah. And you're probably going to throw an exception. So yeah, anyway. Cool. So you probably should get your code write, test it and then just stick it in GitHub. Getting your repository, make sure it's all up to date, right. Oh, I was wondering how you're gonna do that transition. So yeah, that's good. I was following a discussion on Twitter. And I think I actually think Anthony Shah may have started it, but I can't remember. But dealing with different if you've got a lot of repositories, just sometimes you have a lot of maintenance to do, or a little, you know, some common things you're doing for a whole bunch of repos. And there's lots of different reasons why that might be the case or related tools, or maybe just your work. You've got a lot of repos. But there's a project that came up this discussion that I hadn't really played with before. And it's a project called my repos. And on the site, it says, You've got a lot of version control repositories, sometimes you want to update them all at once, or push out all the local your local changes, you may use special command lines in some repos to implement specific workflows. Well, the my repos project provides an EMR command, which is a tool to manage all your version control repositories. In that the way it works is it's on directory structures. So it's a and I usually have all of my repos that I'm working with under under a common like projects directory or something so that I know where to look. And so I'm already set up for something like this might work. And you go into into in one of your repos, and you type, if you have this installed, you type in my register, and it registers uh, this under registers that repo for common commands. And then whether you're in a parent tree, parent directory, or one of the specific directories and type of command like for instance, if you say, Mr. status, it'll do status on all the repos that you care about, or update or diff or something like that. And then you can build up even more complex commands yourself to do more complicated things. But I would I mean, I'm probably going to use it right away just for just checking the status or doing polls or updates or something like that on lots of repos. This looks nice. Yeah, it looks neat. I like the idea a lot. So basically, I'm the same as you, I've got a directory, maybe a couple levels. But all of my GitHub repos go in there, right? I group them by like personal stuff for work stuff. But other than that, they're just all next to each other. And this is just like you say, go do a git pull on all of them. That's great. Yeah. Or like, for instance, I work I've got often like three or four different related repos that if I switch to another project that I'm working on, I need to go through and make sure I'm not sure what branch I'm using, or if everything's up to date. So being able to just go through all like even two or three, being able to go and update them all at once, or just even check the status of all let's save time. And then from to show, at least somebody that interviewed for testing code, at least Adam Johnson wrote an article called maintaining multiple Python projects with my repos and we'll link to his article in the show notes. Yeah, perfect. I like this idea enough that I wrote something like that already. You did. Well.

00:25:00 What I wrote is something that will, it'll go and actually synchronize my GitHub account with a folder structure on my computer. So I'll go and just say, like, repo sync, or whatever I call it. And it'll use the GitHub API to go and figure out all the repos that I've cloned, or created, and the different organizations like talk Python organization versus my personal one, and then it'll create folders based on the organization or where I forked it from, and then clone it. And if it's already there, it'll update it within, it'll like basically pull all this down. That's cool. I need that. It was a lot of work. This seems like it's pre built and pretty close. So it looks pretty nice. It does. One thing it doesn't do is it doesn't look like doesn't go to get up and say, oh, what other repos Have you created that you maybe don't have here? Or maybe you want that maybe you don't if you've like, forked windows source code, and it's like 50 gigs, you don't want this tool that I'm talking about. But if you've reasonable size things, like I forked to Linux, okay, great. That's gonna take a while. But normally, it would be. I think it'd be pretty neat. Yeah. Another thing that's neat around managing these types of things is Docker. And did you know that Python has an official Docker image? I did not. I didn't either. Well, I recently heard that, but it's fairly new news to me that there's an official Docker Python image of, theoretically, if you want to work with some kind of Linux Docker machine that uses Python, you can go and Docker run or to create the Python one, right? So it's not super surprising. It's just called Python, right? But it's just called Python. That's it, I believe. So pretty straightforward. Working with it. But I'm going to talk about, like basically looking through that Docker, that official Docker image. So Mr. Turner towering, he was on top, I thought Not long ago talking about Phil, I also talked about Phil, and by them bytes, the data science focused memory tool, he wrote an article called a deep dive into the official Docker image for Python. So basically, it's like, well, if there's an official Docker image for Python, what is it? How do you set it up? Because understanding how it's set up is basically, how do you take a machine that has no Python whatsoever and configure it? In a Python way? Yeah. So this is using Debian. That's just what it's based on. And it's using the Buster version, because apparently, Debbie, and names all their releases after characters from Toy Story. I didn't know that. But Yep, the monster Buster is the current one. So it's gonna create a Docker image, you create the Docker file, I say this Docker image is based on some other foundational one, so Debian buster, and then it sets up slash user slash local slash bin for the environmental path, because that is the first thing in the path, because that's where it's going to put Python. It sets the locale, explicitly to the end language is to UTF. Eight. There's some debate about whether this is actually necessary, because current Python also defaults, UTF, eight, but you know, here it is. And then it also sets an environment variable, Python underscore version two, whatever the Python version is, right now, it's 385. But whatever it is, that's kind of cool. So you can ask, Hey, what version is in this system without actually touching Python? That's good. And then it has to do a few things like register the CA certificates, like I've had people send me messages or taking courses, or trying to run the code from something that talks to request, whether it is SSL certificate endpoint as an HTTPS endpoint. And they'll say this thing says the, the the certificate is invalid, the certificates not valid, what's going on here, right. And almost always, something about the way that Python got set up on their machine didn't run the Create certificate command. So there's like this step where Python will go download all the major certificate authorities and like trust them in the system. So that happens next. And then it actually will set up things like gcc and whatnot. So it can compile it does interesting, downloads, the source code, compiles it, but then what's interesting is it uninstalls the compiler tools. It's like, okay, we're going to download Python, and we're gonna compile it. But you didn't explicitly ask for GCC, we just needed it. So those are gone. Right? cleans up the pi c files and all those kinds of things. And then it gives an alias to say that Python three is the same as Python, like the command you could do it with or without the three. Another thing that we've gone on about that's annoying is like I created a virtual environment. Oh, it has the wrong version of PIP is my PIP out of date. Your PIP is probably out of date, everyone's PIP is out of date. Unless you're like a rare like two week window, where Python has been released the same time like the modern PIP has been released. So guess what? They upgrade PIP to the new version, which is cool. Yeah. And then finally

00:30:00 It says the endpoint sorry entry point of the Docker container, which is the default command to do if you just say Docker run this image like Docker run Python, three dot eight dash slim dash buster, if you just say that by itself, what program is going to run because the way it works is it basically starts Linux and then runs one program and that program exits the Docker container goes away. And so it sets that to be the Python three command. So basically, if you Docker run the Python Docker image, you're going to get just the repple. Hmm, interesting. Yeah, you can always run it with different endpoints like bash and then go in and like do stuff do it, or run it with micro whiskey or nginx or whatever. But if you don't, you're just going to get Python three rebel. Anyway, that's the way the official Python Docker image configures itself from a bare Debian Buster over to Python three neat, yeah, neat. I thought it might be worth just thinking about, like, what are all the steps? And you know, how does that happen on your computer? If you know that is good? Because Yeah, I have been curious about that. I was gonna throw Python on Docker image. What does that get me? And yeah, it is. You could also apt install Python three, dash Dev.

00:31:18 That might be cheating. Alright, what's this final one? Oh, so it was recommended by we covered some craziness that Anthony did episode two ago. And somebody commented that maybe we need a only independent mix section. So yeah, that sounds fun. So I selected a nano most nano sorry, nano nest. It's optimal peanut butter and banana sandwich placement. So this is kind of an awesome article by Ethan Rosenthal, talks about during the pandemic, he's been sort of having trouble doing anything. And so he really liked peanut butter sandwich, peanut butter and banana sandwiches when he was just still even he got picked this habit up from his grandfather, I think, anyway, this is using Python and computer vision and deep learning and machine learning, and whole bunch of cool libraries to come up with the best packet packing algorithm for a particular banana and the particular bread that you have. So you take a picture that includes both the bread and the bananas, or the banana you have, and it will come up with the optimal slicing and placement of the banana for your banana sandwich. Wow, this is like a banana maximization optimization problem. So if you want, you got to see the pictures together. So like, if you're going to cut your banana into slices, and obviously the radius of the banana slice berries that where you cut it in the oven, and right near the top is in the middle. It's gonna result in different sized slices. On where do you place your bread, the bananas circles on your bread to have maximum surface area of bananas relative to the what's left to the bread, right? Something like that. Yes, please drink to the maximum make it so that you have almost all of the bytes of the sandwich have an equal ratio of banana peanut butter and bread. Oh, yeah. Okay, it's all about the flavor. I didn't understand, like the real motive motivation. But yeah, you want to have a, an equal layer, right? So the you want that spot where you just get bread, you can actually learn quite a bit about all these different processes. And and there's quite a bit of math here, talking about coming up with arcs for if to estimate the banana shape as part of an ellipse. And using the radius of that determine banana slices and estimates for because you're looking at a banana sideways, you have to estimate what the what the shape of the banana circle will be. And it's not really a circle. It's more of an ellipse also. Yeah, there's a lot going on here.

00:33:52 Some advanced stuff to deliver your bananas perfectly. I love it. Actually, this is really interesting. This is cool. And it's I mean, it's a silly application. But it's also a neat example. Yeah, actually, and this would be I think a cool thing for to talk about difficult problems and packing for like a teaching like in a in a school setting. I think this would be a great example to talk about some of these different complex problems. Yeah, totally. Well, that's it for our main items. For the extra as I just wanted to say I'll put the links for the Excel Python webcasts in the memory management course down there, and we'll put the Patreon link as well. Let's see you have anything else you want to share? No, that's good. Yeah. Cool. How about sharing a joke? A joke would be great. So I'm gonna describe the situation and you can be the interviewer slash boss, who has the caption, okay. Okay. So the first there's two scenarios, the title is job requirements. This comes to us from Eduardo or a channel. Thanks for that. And the first scenario is the job interview, where you're getting hired. And then there's the reality which is later which is

00:35:00 The actual on the job day to day so on the job interview, I come in I'm an applicant here and Brian the boss says inverted binary tree on this whiteboard or some other random data structure like quicksort this but but using some other weird thing, right? It's something that is kind of really computer sciency way out there. Probably not going to do but kind of maybe makes sense, right? All right now we're at I'm at the job and I've got like a my computer. I have a huge purple Buy button on my website that I'm working on. And the boss says make the button bigger.

00:35:32 Yep, that's the job.

00:35:36 Yeah, very nice. Good, good. All right. Well, I love the jokes and all the tech recovering. Thanks, Brian. Yeah, thank you. Bye. Thank you for listening to Python bytes. Follow the show on Twitter via at Python bytes. That's Python bytes as mb yts and get the full show notes at python bytes.fm. If you have a news item you want featured just visit Python by set FM and send it our way. We're always on the lookout for sharing something cool. On behalf of myself and Brian knockin. This is Michael Kennedy. Thank you for listening and sharing this podcast with your friends and colleagues.

