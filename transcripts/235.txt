00:00:00 Hello, and welcome to Python bytes where we deliver Python news and headlines directly to your earbuds. This is Episode 235 recorded may 26 2021. And I'm Brian Aachen. I'm Michael Kennedy. And I'm Vincent warmerdam. We talked about Vincent A while ago and got his name wrong. And he told us a story that was good. That, that we accidentally pronounced his name.

00:00:24 But wonderment, yes.

00:00:27 So sorry about that. That's fine. It's fine. I was bragging to my wife that I was on the podcast. And then I was announced as fincen wunderman. And she's still kind of philosophical about the whole thing, but it was it was a fun introduction. That's the best, best best mispronunciation of my life. Let me put it that way. It's, it's your alter ego. by name.

00:00:46 I'll take it.

00:00:48 Well, thanks for joining us today. My pleasure to jump into the first topic. Sure. Okay. Well, I think we covered we mentioned last time that flask 2.0 was out. And and then Michael had done you had you talked with somebody, didn't you?

00:01:06 I did. I had david Lord. And also Philip Jones on talk Python to basically announced last two Oh, and talk about all their features. Yeah, then. And that was a great episode. Listen to both those. Listen, that was great. The, what I wanted to cover was a couple articles, or an article and video. So first off, we've got a link to the change lists. So if actually lost the change list? Yeah, there it is. So you can read through that. And maybe that's exciting to you. But I like a couple other ways. So there's a

00:01:43 an article by Patrick Kennedy, a sink and floss 2.0. And I really liked this this article, it goes through kind of describing what it means to have a sink in flask and how it works with some nice little diagrams. It's diagrams are always nice. Yeah, yes. Pictures, yes. And then a description of the hsgi. And why we don't need it yet. And I'm not sure that may, I'm not sure what the framework the timeline is for, for flask if they're going to do it more, but there is a discussion of that it's not completely a sake. Yet, there was a lot of discussion with David and Philip, that they may be leaving court to take the place of full on, okay, a SGI flask. And the idea being that there's, there's a lot of stuff that kind of has to change, especially around the extensions, and you get nearly that, but not exactly that by using the G event async stuff that's in regular flask. And that integrates in if you just do an async def method in your regular flask, but if you want true async IO integration, then they basically were saying for the time for the foreseeable future, instead of import flask and go and not just import core in where we see flash, replace it with the word court, okay.

00:03:05 And then spent, there's other there's other cool stuff other than they think that's coming into class 2.0. So appreciate it. There's also a video from we don't want it to play from Miguel Greenberg.

00:03:18 And talk talking about some of the some of the new stuff in in flask. And really like this, one of the things that is, uh, he covers right away is the new route decorators. And that's a nice might be just a syntax thing. But it's really nice. So used to have to say app route. And then methods equals poster math, you know, the method. And now you can just say a post. That's nice. And then a really clean discussion of the WebSocket support with flask. And then goes he goes into talk about the async. And with that also does a little demo, timing it. And I was actually surprised at how how, like how easy it was to set up this.

00:04:01 This demo of timing. And showing that he showed that you can increase the users and then still and still get it doesn't really increase your response time, or how many, how many

00:04:15 users per request per second isn't increased because of the way the last 2.0 was done. But it was nice. And then he also talked about some of the extensions that he wrote to that work with plus 2.0 and stuff. So it was definitely worth the listen. Oh, that's always cool. That's always the thing when you get like a flash like a pretty big project. So when there's like a new upgrade of that, one of the things that people sometimes forget is like, oh, what, like all the plugins do, they kind of still work? So it's nice if someone does a little bit of the homework there and sort of says, Well, here's a list of stuff that I've checked, and that's at least compatible. Well, he's mostly doing some stuff. For instance, one of the things is around,

00:04:52 which I don't know which just some of the WebSocket stuff has changed and some of the other things have changed and he has like some more

00:05:00 some different shims that he was used recommending the same things before. But now, you don't have to do you don't have to swap out some things. So like, for instance, some of the extensions, were allowing for WebSockets required you to swap out the server for a different server and you don't have to anymore. Like

00:05:19 that. Cool. Yeah, a couple big. Other things that come to mind. One, they've dropped Python two support, and even three, five and below. I mean, we're at this point where three five is like old school legacy, which surprises me, I still feels new. Yeah, I remember when it came out. Yeah, well, that was when async and await arrived. Right. So that was a big, big deal there. But it doesn't have f string. So it's, yeah, that's the killer feature. Yeah.

00:05:46 Yeah. So there's that. And they also said that you are not going to change your deployment infrastructure. If you want to run async flask, you can just push a new version, and it's good to go. So yeah, a lot. A lot of neat things. They're very good. Nice. Um, we're getting next.

00:06:03 Well, what if I thought were faster? That would be nice. That's always good. We actually talked about Cinder, you remember? Cinder? Yeah, based from the Facebook world. So that's one really interesting thing that is happening around Python. And there's a lot of cool stuff here. But remember, this is not supported. It's not meant to be a new runtime, just there to give ideas and motivation and and examples and basically to run Instagram. On the other hand, Mike Driscoll tweeted out, hey, Python might get a two times speed up in the next version of Python. And you might want to check out either slides from the Python language summit at the virtual Python. That's exciting, right? Yes. I mean, yeah, if ghido is saying it, then you know,

00:06:50 odds of it happening increased, right? Exactly, exactly. So a while ago, we actually covered what is now become known as the Shannon plan

00:06:59 for making Python faster, a little bit each time over five years, over the next four, at least, I guess, four years at that point, and how to make that happen. So some of these ideas come from there. And so here, I'm pulling up the slides. And he says, Can we make c Python faster? If so by how much? Could it be a factor? or two? Could it be a factor of 10? And do we break people if we do things like this? So the Shannon plan, which was posted last October, and we covered talks about how do we make it 1.5 times faster each year, but do that four times and because of compounding performance, I guess, cats five times faster. Alright, so there's that. You just said thank you to the pandemic, thank you to boredom, I decided to apply at Microsoft and shocker they hired him.

00:07:47 So as part of that, it's kind of just like, Hey, we think you're awesome. Why don't you just pick something to work on that will contribute back? That'd be really cool. So his project at Microsoft is around making Python faster. But I think it's great. Cool, though. Yeah. So there's a team of folks, Mark Shannon, Eric snow, and ghido, and possibly others who are working with the core devs. At Microsoft to make it faster, which is really cool. Everything will be done on the public GitHub, GitHub repo, there's not like a secret branch that will be then dropped on it. So it's all just gonna be prs to github.com slash Python, slash C, Python, whatever the URL is the public spot, and one of the main things they want to do is not break compatibility. That's important. also said, what what things could we change? Well, you can't change the base object like, Hi, oh, was that by OBJ? The basically the base class, right? Pi object pointer. That's it the PI object class. So that thing has to stay the same. And it really needs to keep reference counting semantics, because so much is built on that. But they could change the bytecode that exists, the stack frame layout, the compiler, the interpreter, maybe make it a JIT compiler to JIT, compile the bytecode, all of those types of things. So that's pretty cool. They said, How are we going to reach two times speed up in 311, an adaptive specialized bytecode interpreter that will be more performant around certain operations, optimize brain stacks, faster calls, zero overhead, exception handling, and things like integral internals, maybe treating numbers differently. png files, there's a lot of stuff going on also, putting the Dunder dict for a class always had a certain known location, because anytime you access a field, you have to go to the Dunder dict, get the value out and then read it. And I suspect the first thing that happens is we'll go find the Dunder dict pointer, and then go get the element out of it. So if every access could just go, nope, it's always you know, one certain bite off in memory from where the class starts. That would save you know, that sort of reversal there. So some pretty neat things. Yeah. I'm going to explain

00:10:00 Cuz I read it before and why would that help at all? I think it I think you can traverse when fewer pointers

00:10:08 in general doesn't matter. But it literally everything you ever touch ever. If you could cut in half the number of pointers, you got to follow that be good. Yeah, this is always one of those things that always struck me with when you're using Python, you don't think about these sorts of things is when you when you're doing something in rust or something, then you are confronted with the fact that you really have to keep track of where's the pointer pointing and memory and all that you take a lot of stuff for granted. So it's great that people are still sort of going out and looking for things to improve their Yeah, absolutely. You know, and like, see, do the arrow, you know, dash greater than sort of thing, every pointers here, like I'm following a pointer, a pointer, like you know it right here, you just you write nice clean code and magic happens.

00:10:47 So let me round this out with who will benefit. So who will benefit if you're running CPU intensive, pure Python code, that will get fast, because the Python execution should be faster? websites should be faster, because a lot of that code is running in the Python space. And was it happen to use Python who will not benefit so much NumPy, TensorFlow and as all the code that's written and see things that are IO bound, so if you're waiting on something else, to beating up the part that goes to wait, really matter, multi threaded code, because of the Gil at this point, but Eric's now is also working on the sub interpreters, which may fix that and so on. So I like the last.

00:11:26 There's some peps out there, I'll link to I like to the wheat by Mike Driscoll. But that'll take you straight to the GitHub repo, which has the PDF of the slides, and people can check that out if they're interested. I like the last bullet for the previous slide, things, people that will not benefit code that's algorithmically inefficient. Otherwise, if your code already sucks, it's not going to be better.

00:11:50 It made me better. I better, say like, theoretically, it actually would go faster, and just

00:11:57 just not as much better as, yeah, it still be like n to the power three or something like that. But it would be faster and to the power three. Yeah, it won't change the the big O notation, but it might make it run quicker on wall time. That's right. Yeah. Yeah. And Christopher Tyler out there, the live stream says, I know, I still need to prove my code. But this would be great, right? I mean, it used to be that we could just wait six months, a new CPU would come out that's like twice as fast as what we ran out before I got now it's fast or good. That doesn't happen as much these days. So it's cool that the runtimes are getting faster. Yeah, I mean, let's let's be honest, Python is also still used for like just lots of scripts, tasks, like, Hey, I just need this thing on the command line that does the thing. And I put that in Chrome. And like a lot of that will be nice if duck just gets a little bit faster. And it sounds like this will just be right up that alley. Yeah. And one of the things that I know has been holding certain types of changes back has been concerned about slowing down the startup time. Because if all you want to do is run Python to make a very small thing happen, but like there's a big JIT overhead and all sorts of stuff. And it takes two seconds to start no nanosecond microsecond to run. Right. They don't want to put those kinds of limitations and kill that use case either. So yeah, it's it's good to point that out. All right, Vincent, you're up next. Cool. Yeah. So I dabble a little bit in fairness algorithms. So it's, it's a big important thing. So I get a lot of questions from people like, hey, if I want to do like machine learning and fairness, where should I start, and I don't think should start with algorithms. Instead, what you should do, you should go check out this Python project called Dion. And the project's really minimal. The main thing that it really just does, is it gives you a checklist. So just stuff to check, before you do like a big data science project that a, like a big company or an enterprise or something like that. And they're really sensible things. They're they're sort of groups together. So like, Hey, can I check off that I have informed consent and collection bias can like Can I check all these things off? The main themes, it's literally a checkbox, you can check them off in the page to sort of get the feel that like, Oh, yeah,

00:13:58 it goes further. So the thing is, this is an actual Python project, you can generate this as yamo for your GitHub profile. So like for your GitHub project, you actually have this checklist that has to be checked in git, so people, so you know, that people signed off on it. Like you can actually see the checklist you can even maybe you're good luck, see who checked it off. But what's really cool is two things. One, you can generate this checklist, too. You can also customize the checklist. So if you are a specific company have certain legal requirements, this tool actually kind of makes it easy to customize is very specific checklist for data projects. But the real killer feature if you ask me like, again, all of these comments are good, like, is the data security? Well done? Is the analysis reproducible? How do we do deployment like all of these things that are usually like things that go wrong, and we're obvious in hindsight, but the real killer feature is usually have to convince people to take this serious. So what the website offers is like an example list. So for every single item that is on this checklist, they have one or two examples. Typically these are like newspaper articles of places where this has actually gone wrong in the past. So if you need like

00:15:00 Like a really good argument for your boss, like, Hey, we got to take the series, there's a newspaper article you can just send along as well.

00:15:07 That's interesting. Yeah. It's like it's Yeah, no. And the fact you can also generate Jupyter Notebooks with this, you can customize it a little bit. The people that made this, the company, I think, is called driven data. They hosted kaggle competitions for like good causes that sort of thing that they do there. But the on, it's just a really cool project. Like I think if more people would just start with a sensible checklist, and work from there. A lot of projects would immediately be better for it. Yeah, this is this is really cool. And so things her Can you go to the very bottom of that page? That Yeah, yeah. Sorry, the just the checklist. All right. Yeah. So there's some examples, like, make sure that you've accounted for unintended use, have you taken steps to identify and prevent unintended uses and abuse. So like, you created up, find my friends, and pictures. So like, I want to find pictures, my friends have taken me You could put it up, and it would show you all the pictures your friends took, but maybe someone else is going to use that to, you know, try to fish you like, here's a picture of us together, or I don't know, some some weird thing. And I use it for like facial recognition and tracking when it had no such intent, right? Things like that. I think I might be about so it's didn't it doesn't have this example, the best example of unintended use, there used to be this geo lookup company where you could give an IP address and give you like an actual address. However, sometimes you don't know where the IP address actually is to just give like the center point of like a US state or the country. So there used to be this house in the middle of Kansas, I think it was like the center point. But the thing is, this, they will get like FBI trucks driving by and like doing raids and stuff, because they thought there were criminals there. Because the geo lookup services always say like, oh, the crooks at that IP address. That's this latitude longitude place. Right, right. We had a cyber attack. It was from this is great. And boys. Of course, he was just at some poor farmer in the Midwest going, you know, yeah. Now, the geographic center, please stop raiding my farm. Yeah, but

00:17:02 the story was actually quite serious. Like, I think the person will if they're good, like death threats at some point as well, because of the same mistake. So we'd like this stuff to take serious. The one thing I did like is the solution. I think now the instead of it pointing to the house in Kansas, I think it points to like, the center of the three big lakes in Michigan, I think I just the middle of a puddle of water, basically, just to make it out. Like obviously, the FBI squats like not it's not a person living there. Yeah. But like, darn the submarine cert that they've moved underwater, or, or whatever. But, but that's why you want to have a checklist like this, like you're not going to the thing of unintended use is it's unintended. So you cannot really imagine it. But you had Leisha do the exercise, and that's what this list does in a very sensible way. And more people should just do it. And that's interesting samples to just have a look. And it's also a little interesting. There's a little community around it as well, like collecting these examples. And they have like a wiki page with examples that didn't make the front page cut. So definitely recommend anyone interested in fairness, start here. Um, I was curious, you first read it fairly quickly of fairness and fairness analysis? Is that what you do? So they just don't know what that means? So could you? Yeah, so this is a longer like, this topic deserves more time than I'll give it. But the idea is that you might be able, we know that models aren't always fair, right? Like, it can be that you have models that, for example, the Amazon was a nice example. So they had like a resume parsing algorithm that basically favored men because they hired more men historically. So the algorithm will prefer map. Okay, so far kind of fairness. Okay. Yes, Oracle, these have been our good employees, let's find more like them exact. So as I said, And the thing is, you don't get an algorithm that's unfair. So there are these machine learning techniques. And there's this community of researchers that try to look for ways like, can we improve the fairness of these systems, so we don't just optimize for accuracy. They also say, well, we want to make sure that subgroups are treated fairly and equally and stuff like that. So I dabble a little bit in this, there's this project, I like to collaborate with my open source a couple of things with these people. It's called fair learn. The main thing that I really like about the package is that it starts by saying fairness of AI systems is more than just running a few lines of code. Like it starts by acknowledging that, but they have mitigation techniques and algorithms and like tools to help you measure the unfairness cycle are compatible as well and stuff to like, settle that. Start here. Start with a checklist. Don't worry about the machine learning stuff just yet start here. But yeah, pretty cool. Move on Connor burster. In the live chat says I'm glad the conversation of ethics and data science is enlarging. I think it's important about what we make. I agree. Totally. Now before we do move on, though, let me tell you all about our sponsor for this episode. century. So this episode is brought to you by century Thank you century, how would you like to remove a little bit of stress from your life, you worry that users may be having difficulties or

00:20:00 we're encountering errors with your app right now. And would you even know it until I sent you that support email? How much better would it be to have the errors and performance details immediately sent to you, including the call stack and values of local variables, and the active user recorded right in the report was century, it's not only possible, it's simple. And we actually use Sentry on our websites, it's on Python, bisetta FM, it's on top Python training all those things. And we've actually fixed a bug triggered by a user and had the upgrade, ready to roll out. As we got the support email, they said, Hey, I'm having a problem of the site. I can't do this or that I said, Actually, I already saw the error, just push the fix to production. So just try it again. Imagine their surprise, surprise and delight your users get your century account at Python by setup m slash century. And when you sign up, there's a got a promo code redeem it, make sure you put Python bytes in that section, or you won't get coupons every century team plans and other features and they won't know it came from us. So use a promo code at Python bytes FM slash century. Yeah. Thanks. Thanks for supporting the show. Brian. Yeah, I liked this one that you picked here. You like this? I like it a lot. It's very good. It has pictures, little animated things. And great looking tools. Yeah, so there's a was an article it was sent to us. I can't remember who said it. So apologies. But it's an article called three tools to track and visualize the execution of your Python code. And I'm just, I don't know why executing your code just seems funny to me. I know. It just means run it but it you know, chop its head off or something. Anyway.

00:21:31 So the three tools, the three tools he covers are a lot, that we don't cover this very much, because I don't know how to pronounce it. LG u r u, it's log guru or logger Ru? Not sure. And then so log Guru is a pretty printer with better exceptions. So let's,

00:21:50 let's go and look at that. So it does exceptions like this, like breaks out your exceptions into colors. And it's just a really great way to visualize it. And I would totally use this for if I was teaching like it was teaching a class or something, this might be a good way to teach people how to look at trace logs and error logs. This is fantastic. And if you're out there listening, not seen it, you should definitely pull up this site, because the pictures really are or what you need to tell quickly. Yeah, yeah. That's one of the things I like about this article is that lots of great pictures. So one thing out of curiosity. So what I'm seeing here is that, for example, says return number one divided by number two, and then you actually see the numbers that were in those variables. But they have to do you have to add like a decorator or something to get this output or how does that work?

00:22:39 That's explained later, maybe? I don't remember. Where, where Yeah, it's explained later, I think Yeah, yeah, I think he just pull it in. And it just does it. But I'm not sure.

00:22:50 The so the other so that's lager. Then there's Snoop, which is, which is kind of fun. That has

00:22:59 learned to snoop should have this already. Anyway, you put with Snoop, you can see in Princeton lines of code being executed in a function. So it just runs your code and then prints out each line in real time as it's going through it.

00:23:15 You would hardly ever want this, I think, but when you do want to think might be kind of cool to watch, watch it going along. And it it's a, you could also do this in a debugger. But if you didn't want the debugger to a debugger, you can do this on the one of the things that most debuggers have that is a little challenging is you'll see the state and you'll see the state change, and you'll see a change again. But in your mind, you've got to remember, okay, that was a seven, and then it was a five and then it was a three. All right, yeah, right here, it'll, it'll actually reproduce each line, each block of code with the values over if you're in a loop three times, it'll show like going through the loop three times with all the value set. And that's pretty neat. Yeah, I would also argue just for teaching recursion, I think this visualization is kind of nice, because you see that you actually see like the indentation and the depth appear. So you can actually see like, this function is called inside of this other function, and there's a timestamp. So I'm, I would also argue, this one's pretty good for teaching. I like it. In fact, Connor, on the livestream says, I'm teaching my first Python course tomorrow. So yeah, thanks for this timely article. And real time follow up for the log guru, you have to import logger, and then you got to put a decorator on the function and then it'll capture like that super detailed output. Oh, then that's, that's probably exactly what you want. Because you don't really want to do that for everything, probably. So there'll be something you're working on that you want to trace. So heart rate is the last tool that we want to talk about and visualize. It's, it's a way to visualize the execution of a Python program in real time. So this is something we have not covered before, but it's that there was a little video. Yeah. It kind of goes through and does a little, like a heat map, sort of

00:25:00 thing on the side of your code. So when it's running, you can kind of see that different things get hit more than others. So it's almost like a profiler. Sort of not speed, though. It's just number of hits. Yeah. Yeah, ma'am. I'm kind of on the fence about this, but it's pretty. So. Yeah, same. But the logger ruin looks amazing. I thought logger Roo was also like a general logging tool. Like it does more I think than just things for, for debugging. Yeah, I think it's a general logging tool as well. Okay. Okay. But I guess it logs errors really good.

00:25:40 So, logger dot catch decorator, okay. could probably do other things with the logger then as well. But having a good logging debugger catcher is always welcome. Yeah, absolutely. All right. Let's talk about ducks. I mean, Brian, you and I are in Oregon. Go ducks. Is that it? Well, I know your daughter goes there. My daughter goes to us, OSU. So go, go be us. I guess it'll be whatever ducks were talked up databases anyway. And data science. So Alex Monahan sent over to us, saying, hey, you should check out this article about duck dB, which is a thing I'm now learning about. And it's integration. It's direct integration with pandas. So instead of taking data from a database, loaded into a panda's data frame, doing stuff on it, and then getting the answer out, you basically put it into this embedded database doc dB, which is SQL lite, like, and then No, sorry, you put it into a panda's data frame, but then the the query engine of wb can query it directly without any data exchange without transferring it back and forth between the two systems or format. That's pretty cool, right? So let me pull this. Oh, that's how much I know him. Nice. Nice.

00:26:48 Yeah, very cool. So here's the idea. We've got SQL on pandas. Basically, if we had a data frame, do they have a really simple data frame, but just, you know, a single array, but it could be a very complex data frame. And then what you can do is you can import doc dB, and you say duck DB query, and then you write something like so one of the columns is called a in the data frame. And you could say, select some of a from the data frame. How cool is that? I don't know. Is it cool? It's very cool. So then you could also there's also a to data frame on the result. So what happens here is this is parsed by duck dB, which has an advanced query optimizer for things like joins and filtering and indexes and all that kind of stuff. And then it says, oh, okay, so you said there's a thing called my df, which I'll just go look in the locals of my current call stack and see if I can find that. Yeah, that is the so you can write arbitrary SQL. And this one looks pretty straightforward. Yeah. Yeah. Okay. Interesting, interesting. But you can come down here and do more interesting things. Let's see a pull up some examples. So they do a select aggregation group by thing. So select these two things. And then also do a sum min max and average on some part of the data frame. And then you pull it out of the data frame and you group by the elements, right? And they show also what that would look like, if you did that in true pandas format. That's cool. And they say, well, it's about two to three times faster in the web version. That is interesting. That's interesting, right? But then they say, Well, what if we wanted not to just group by, but we wanted a filter seems real simple, like where the ship date is less than 1998. No big deal. But because the way that this be really officially figured out by the query optimizer, it turns out to be much faster. So point six seconds on single threaded, or it actually supports parallel execution as well. So multi threaded, they tested on a system that only had two cores, but it can be many, many cores, though. It's faster point four seconds, when threaded versus 2.2 seconds. Alright, 3.5 seconds on regular pandas. But there's this more complicated, non obvious thing you can do called a manual pushdown in pandas, which will help drive some of the efficiency before other work happens. And then they finally show one at the very end where there's more stuff going on, like your query optimizer does. So the threaded ones point five seconds, regular pandas is 15 seconds. So all that's cool. And what's really neat is it all just happens like on the data frame. Now, there's two things about that, that are pretty interesting. Like one is we shouldn't underestimate how many people are still new to pandas, but do understand SQL. So just for that use case, I can imagine, you know, yeah, I get a lot point, you're gonna get a lot of people on board. But the fact that there's a query optimizer in there that's able to work on top of pandas, that's also pretty neat, because I'm assuming it's doing clever things like, Oh, I need to filter data. I should do that as early on as possible. And my query plan is doing some of that logic internally. And the fact is, you can paralyze it because parallel penance doesn't paralyze easily.

00:30:00 Yeah, I don't know that it paralyzes at all you got to go to something like dask Yeah, I mean, so there are these there are some there are some some tricks that you could do, but there are tricks, they're not really natively supported.

00:30:11 Right. But just having a sequel interface is neat. Yeah, yeah, this is pretty neat. And also now I learned about duck dB. So apparently that's a thing, which is pretty awesome. So it's, it's in process just like SQL lights written in c++ 11, with no dependencies, was to be super fast. So this is also a cool thing that you know, maybe I'll check out unrelated to query and pandas. But the fact that you can think is pretty cool. It's got a great name. Yeah. You know, another database out there I hear a lot about but I've never used I have really an opinion about cockroach dB. I'm not a huge fan of just on the the name, although it has some interesting ideas. I think it's like meant to communicate resiliency, and it can't be killed because it's like, geo located and it's just going to survive. But yeah, ducks. I'll go with ducks. Yeah, I would agree. Yeah. And then chat out in the livestream chat, Christopher says so Dr. B is worrying on pandas dataframes? Or can you load the data method chain with duck DB and reduce memories? I believe you could do either, like you could load data into it. And then there's a two data frame option that probably could come out of it. But I think I think just breezed right on it. Yeah, doesn't, I might have just seen a briefly waltz while you were scrolling in the blog post. But I believe it also said that it supports the parquet file format. So the nice thing about parquet is you can kind of index your data cleverly, like you can index it by date on the file system. And then presumably, if you were to write the SQL query in duck dB, it would only read the files with the appropriate date if you put a filter in there. So I can imagine just because of that reason, duck DB on its own might be more memory performance patterns, I guess. Perhaps that's cool. Stuff like that. You could do? Yeah. And then Nick Harvey also says wonder if it's read only if you can insert or update? I don't know for sure. But you can see in some of the places they are doing like projections. So for example, they're doing a select some min max average, like that's generating data that goes into it. And then the result is a data frame. So you can just add into the data frame afterwards, if you want to be more manual about it. Yeah. All right. And then you got the last one. Yeah. So the thing is, I work for a company called Raza, we make software and with Python to make virtual assistants easier to make in Python. And I was looking in our community showcase on this, I found this project that just made me kind of feel hopeful. So this is a personal project, I think. So we have a name here, a meet, and I'm hoping pronouncing it correctly, Arvind, but what they did is they used Raza kind of like a Lego brick, but they make this assistant, if you will, that you can send a text message to now what it does, I'll zoom in a little bit for people on YouTube or they might be able to see the gift. But every 10 minutes, it scrapes the weather information, the fire hazard information. And I think evacuation information from local government in California, meant to help people during wildfire season. And they completely open source this product as well. So there's a linked GitHub project where you can just see how they implemented it. And it's a fairly simple implementation. They use Raza with a Tullio API. They're doing some neat little clever things here with like, if you misspelled your city, they're using like a fuzzy string matching library to make sure that even if you misspell your city, they can still try to give you like accurate information. But what they do is they just have this endpoint where you can send a text message to like, give me the update of San Francisco. And then it will tell you all the weather information, air quality information and that sort of thing. And if you need to evacuate, they will also be able to tell you that and what I just loved about this, if you look at the way that they described it, these, this was just two people who knew Python who were a little bit disappointed with the communication that was happening. But because the API's were open, they just built their own solution. And like 1000s of people use this. And what's even greater is that, you know, if your mobile coverage isn't great, watching a YouTube video, or like trying to get audio in can be tricky. But a text message is really low Blatt bandwidth. So for a lot of people, this is like a great way to communicate. And of course, I'm a little bit biased because I work for Raza, and I think it's awesome that they use rails at the built this app. But again, the whole thing is just open source, you can go to their GitHub, and you can just if I'm not mistaken, there's like the scraping job of the endpoint is actually in here as well. But this is like exactly what you want just a couple of open API's and sort of citizen science building something that's useful for the community. It's great. Yeah, I like it. And text message is probably a really good way to communicate for disasters, right? Yes. Possibly in a place where, you know, LTE is crashed, Wi Fi is out, right? Like, if even if you're on edge, you know, text should still get there. Exactly. Unless you're on iMessage then, you know,

00:34:50 sort of, yeah, so I live in Europe. So I cannot comment on that, of course, but

00:34:56 a little bit different here. But now I'm like the data service, you can just look in here.

00:35:00 And this is like, again, I like these little projects that don't need anyone's permission to help people like that stuff like, This is good stuff. And they'll and the thing that I also really like about it is, it's really just sending you a text message with like air quality information and like enough information. And that's good. It's not like they're trying to make like a giant predictive model on top of this or anything like that. But just really doing enough and enough is plenty like, that's the thing I really love about this little demo. And of course, using Raza, which is great, but this is the kind of stuff that

00:35:30 I this is why I get up in the morning projects like this. That's fantastic. Yeah, I love it. That's a really good one, Brian, and set it up. Yeah, that's it. That's our six items. any extras that you want to talk about? I might have one. Okay. Yeah. Okay. So I'm totally tooting my own horn here. But this is a product I made a little while ago. But I think people might like it. So at some point, it kind of struck me that people were making these machine learning algorithms. And they're trying to like on a two dimensional plane, trying to separate the green dots from the red ones from the blue ones. And I just started wondering, Well, why do you need an algorithm, if you can just maybe draw one. So very typically, you got these like clusters of red points and clusters of blue points. And I just started wondering, maybe all we need is like this little user interface element that you can load from a Jupyter Notebook. And maybe once you've made a drawing, it'd be nice if we can just turn it into a psychic learn model. So there's this project called human learn that does exactly this. It's a tool of little buttons and like widgets that I've made to just make it easier for you to like, do your domain knowledge thing and turn it into a model. So one of the things that it's currently features is like the ability to draw a model, which is great, because domain experts can just sort of put their knowledge in here, it can do outlier detection as well, because if a point falls outside of one of your drawing circles, that also means that it's probably an outlier. But it also has a tool in there that allows you to turn any Python function like any, like custom Python written function into a psychic learn compatible tool as well. So if you can just declare logic in a Python function, that can always be a machine learning model from that one. There's an extra fancy thing, if people are interested, I just made a little blog post about that, where I'm using a very advanced coloring technique using parallel coordinates. Very fancy technique, I won't go into too much depth there. But what's really cool is that you can basically show that a drawn model cannot perform the model that's on the Caris deep learning blog, which I just thought was a very cool little feature as well. The product is called human learn. It's just

00:37:36 components for inside of a Jupyter Notebook to make sort of domain knowledge and human learning and all that good stuff better. And also, with the fairness thing in mind, I really like the idea that people sort of can do the exploratory data analysis bit, and at the same time also work on their first machine learning models of benchmark. That's what human learning does. So people are sort of curious to play around with that. Please do it's open source pip install, please use it. I'm impressed. This is cool.

00:38:02 Yeah, well, Maddie out in the live stream, how does it handle and the data, so and I guess it's three are larger? Yeah. So you can make like, if you have four columns, you can make two charts with two dimensions. That's one way of dealing with it. And there's like a little trick where you can combine all your drawings into one thing. If you go to the examples, though, the parallel coordinates chart that you see here that has 30 columns, and it works just fine. I do think like 30 is probably like the limit. But the parallel coordinates chart, I mean, you can make a sub selection across multiple dimensions that just works. It's really hard to explain the parallel coordinates chart on the podcast.

00:38:40 Yeah, so this is like a super interactive visualization thing with lots of colors and stuff happening. Sorry, you have to go to the docks to fully experience that, I guess. But, but there, but but again, also, like if you, let's say you work for a fraud office, and someone asks you like, hey, without looking at any data, can you come up with rules, that's probably fraud. And you can kind of go Yeah, if you're 12, and you earn over a million dollars, it's probably weird. Like, someone should just look at that. And then the thing is, you can just write down rules that way. And that's your already big can already be turned into a machine learning model. You don't always need data. And that's the thing I'm trying to cover here. Like, just make it easier for you to declare stuff like that. It's a more human approach. I get this. Brian, I cut you off. were you gonna say something? Oh, one of the things. I don't know if we've covered this already, but we've talked about con code that I owe a lot on this podcast, and you're the person behind it, right? Yeah, yeah. Yeah. So it's, it's been a fun little side project that I've been doing for a year now. Yeah. Yeah. So these videos, like go short there. So thanks. So this I like to hit like, people tell me that. And that's also the thing that was kind of going for, like I love the you know, when you watch videos like a lightning talk, and you learn something in five minutes. Yeah. It's an amazing feeling. Like that's the thing I'm trying to capture there a little bit. Like if, if it takes more than five minutes to get a point across then

00:39:56 I should go on to a different topic, but I'm happy to hear you like it. Good. Yes. Very cool.

00:40:00 How about Mike, Michael anything extra as well, I had to now I have three, because I was reading the source code of one of Benson's projects there as we were talking. And I learned about Fuzzy Wuzzy.

00:40:15 So Fuzzy Wuzzy was being used in that emergency disaster recovery awareness thing. It is fuzzy string matching in Python and it says fuzzy string matching like a boss. He got a love. So it was like slight misspellings and plural versus not plural and whatnot. And Brian even uses hypothesis, which is kind of interesting. in protest, and protest, of course, yeah, anyway, that that's pretty cool. I just, I just discovered that. So Fuzzy Wuzzy is a pretty cool tool, the only thing I don't like about it, and this is the one thing I do have to mention. It is my understanding that Fuzzy Wuzzy is a slur in certain regions of the world. That's it. So in terms of naming a package, they could have done better there. But I think the only realize that in hindsight, other than that, there's some cool stuff in there. Definitely. Just when I learned about this, I didn't make the comments of myself. Okay, I should always acknowledge it whenever I talk about the package. But yeah, it's a it's definitely useful stuff in there. Because the string matching is a useful problem to have a tool for. Yeah, very cool. And HP icon where the future 2024 2025 announcement is out. So the next up icons are already, theoretically in Salt Lake City. So hopefully, we actually go to Salt Lake City and not just go and will virtually imagine it was there, right, like this year. But last two years, because of the pandemic Pittsburgh, lost its opportunity to have icon so not just once, but twice, though, they are rescheduling the next one back into Pittsburgh. So folks, they will be able to go and be part of icon. That's pretty loud. But because of Corona, they've not been able to plan for years ahead and the way exactly, it's, everything's upside down now. And then also, I just want to give a quick shout out to an episode that I think is coming out this week on talk Python, I'm pretty sure that's the schedule called code carbon.io. And it is a bank pull it up here. It is both a dashboard that lets you look at the carbon generation the co2 footprint of your machine learning models, as you were specifically around the training of the models. So what you do is you pip install somewhere in here, you pip install this emission tracker, and then you just say start tracking, train, stop tracking, it uses your location, your data center, local energy grid, the sources of energy from all that, and it'll say like, oh, have you actually switched to say the Oregon AWS data center from Virginia, you'd be using more, you would be using more hydro electric rather than, I don't know, gas or whatever. Right. So just we were talking about some of the ethics and cool things that we should be paying attention to. And I feel like that sort of energy impact of model training might be worth looking at as well. So I totally agree with model training. I've been wondering about this other thing, though. And that's testing on GitHub. Like if you think about some of these ci pipelines, they can be big to like, I've heard projects that take like an hour on every commit. I'd be curious to see to run this on that stuff as well. Yeah, well, you could turn on, you could employ this as part of your ci CD. It doesn't really have to do with model training, per se. But it does things like when you train models that use a GPU, it'll actually ask the GPU for the electrical current. Ah, right, right. So hardware, that's

00:43:29 a feature and it goes down to like the CPU level, the CPU level voltage and all sorts of like, low, it's not just Well, it ran for this long. So it's this right. Oh, okay. really detailed. That said, I suspect you could actually answer the same question on on a CI, right, it would just say, Well, it looks like you're training on a CPU.

00:43:47 Yeah. Yeah. But so it's a nice way to be conscious about compute times and stuff. So that's, yeah. And what's cool is it has the dashboard that like, actually lets you explore like, well, if I were to shift it to Europe, rather than train in the US, which who really cares where it trains, but then what difference would that have looked at how green Paraguay is? We're hosting. Yeah, that's incredible. I suspect a lot of waterfalls. Yeah. Countries down there have insane amounts of hydro. Like Chile, maybe I can't remember exactly. But yeah, hydro, AC AC Iceland as well. And it's probably because of the volcanoes and warmth and heat and yeah, yeah, yeah. Okay. Interesting. All right. Brian, you got anything? Not this week? How about we do a joke? Sounds good. So it's been a while since I've been to a Strongest Man, competition. World Strongest Man. You know, like, maybe one of those things where you pick up like a telephone pole and you have to carry this throw it as far as you can, or you lift like the heaviest barbells or like you carry huge rock some distance. So here's one of those things. There's like three judges, bunch of people who look way over pumped. They're all flexing getting ready. The first one is this person here and a huge rock sweating clearly

00:45:00 And the judges are they're not super impressed. They give a five, a two and a six. Then there's another one left in this, you know, 500 pound barbell over his head says eight, seven and six is their score. And then there's this particularly not overly strong looking person here says, I don't code. I don't use Google encoding. Wow. So strong. The judges give them straight heads.

00:45:22 And he's also being like, really sincere, like his hand over his heart. Oh, yeah. Like, it's very humble. Yeah, exactly.

00:45:30 I Well, that's what I got for ya. They can take it for what you will. That's pretty good. Just Stack Overflow. Yeah, yeah. Well, I feel like Stack Overflow would be we give them take it to 11. Honestly,

00:45:42 I don't use Stack Overflow now. The winner.

00:45:47 Definitely. That's funny. Thanks for that. I'm usually pretty good about finding our jokes. Appreciate it. And thanks for coming on the show.

00:45:58 Thanks for having me. It's fun. I think that's a wrap. That is Thanks, Brian. Thank you. Hi, Vincent. Y'all have a good one.

