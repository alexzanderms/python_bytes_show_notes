00:00:00 Hello, and welcome to python bytes, where we deliver Python news and headlines directly to your earbuds. This is Episode 259, recorded November 17 2021. And I'm Brian Aachen.

00:00:11 I'm Michael Kennedy.

00:00:12 And I'm Rene tea. Well, thanks, Renee, for joining us today. Can you tell us a little bit about who you are.

00:00:17 I'm the director of data science at Helio campus. And a lot of people know me as data science, Renee or becoming data sigh on Twitter. So that's where a lot of people follow me. And then I started with a had a podcast that's not actively recording, but it's called Becoming a data scientist podcast. So some people, some people listening probably know me from that as well.

00:00:40 Cool. Yeah. Awesome. You're doing a bunch of cool stuff there. And any chances of maybe going back to podcasting?

00:00:45 It's it's definitely still open. I've never I've always told myself, this is a pause. Not as tough. It's just an extended pause. So yes, hopefully, I

00:00:52 will get it's hard to keep going, isn't it? I mean, yeah, life gets in the way, and then you get busy. And I'm always

00:00:58 so impressed with those of you that have hundreds of episodes very consistently recorded.

00:01:03 Brian makes me show up every week. So

00:01:05 yeah, definitely helps having a partner so that you can coerce each other in. That's right. Um, well, Michael, speaking of partners, tell us about something.

00:01:14 Let's talk about some changes. Some pie pie changes, these come to us from Brian skin. Thank you, Brian, for shooting this over. And it's a project by Brene. Gabor, your. And if we pull this up, it says, Have you ever wondered when did your Python packages the packages in your environment that you have active or any given environment? How old are they? When When When were they last updated? Is there a version of them that's out of date. So I've been solving this by just forcing them to update using PIP compile and the PIP tools stuff to just regenerate and re install the requirements files. But this is a way to just ask the question, what's the status and it wouldn't be an episode if we didn't somehow feature will McGuigan. So this is based on rich, of course. So let's go check this thing out. So over here, if we go to the homepage, we get as all projects should a nice animation here. And if you look at it, you can see type, IPI dash changes, and you specify the path to a Python in a virtual environment. So in this example, is like API changes, V and V slash bin slash Python. It does some thinking on the internet, caches some information about the packages, and it says, Alright, you've got all these things installed there, this version, some of them, it'll just say this was updated 10 months ago, or a year in three days ago. Others it'll say it was updated a year ago, but only six months. On the latest version, it says remote such and such, that's the one you could install if you were to update it. So it's a real nice way to see well, which ones are here that could be updated? Or even also, sometimes it's interesting to know, like, oh, this library, it doesn't have an update, but it's 10 years old, maybe I should consider switching to a library that's a little more maintained and making progress. Right. What do you think that's handy? All right. That's pretty neat. So yeah, I've been playing around with this today installed it checked it out, even pointed out that you know, since yesterday, some things changed in one of my projects that I want to keep up to date. So I updated it. Yeah, so I like it, it's got a nice command line interface, you basically specify the Python that is in the environment that you want to check that could either be the main Python or a environmental, virtual environment, Python, like I said, you can control the caching, because it first time it runs, it has to go get lots of information about each package that's installed. And it's faster the second time, it also has some cool parallelism. So you can say, number of jobs like dash dash jobs, and by default, it runs 10 downloads in parallel as it's pulling this information in. But I guess you could go crazy there. So anyway, I thought this was pretty cool. It's a nice little thing to have. So I PIP X, install this, it's perfect for PIP x, because it doesn't need to be in the project. It's testing. It just needs to be on your machine as a command. And then you point it at the environment, different environments, and it gives you a report on those environments. Yeah, I

00:04:07 love QuickBooks to one of the things I want to note, just I know, a lot of package maintainers having I mean, it's worth checking things out if it's if it's a really old packet if it hasn't been updated for a long time. But some things are pure Python things that just do a little tiny thing and don't need updated very often. So

00:04:25 yeah, it's not necessarily a bad thing that it's not updated, but it's an indicator an indicator Yeah. of something. Yes, exactly. Let's see out in the live audience, Anthony Lister. Hey, says Can the changes be exported to a text file? I haven't seen anything about that other than just, you know, piping it into a text file and who knows what happens with all the color in there, but perhaps, yeah, Renee, what do you do to manage your dependencies and all those kinds of things?

00:04:52 Um, well at work, we started using Docker for that. So we have a centralized Docker container that everyone on my team uses it We make sure we have the same setup in there. So I'm not the one that directly manages it. But but that's the solution that we've gotten towards to make sure we're all on the same page.

00:05:10 Oh, interesting. So you've got the Docker environment that has some version of Python set up with all the libraries you need pre installed, and then you just use that to run and that way, you know, it's the same.

00:05:19 Yep. And then it's also nice, because when we kind of move our some of our projects into production, we can include that Docker container with it. So it will have whatever version it had at the time. So for some reason, it's not compatible with some later version we upgraded to, it still lives out there with the version of the tools that it had until we have a chance to update everything.

00:05:38 One of the challenges that people have sometimes is they say, even though you've got some kind of version management, project, tamo, or requirements, txt or whatever, that doesn't necessarily mean that people actually install them the latest, so you could still be out of sync, right. So having the image that's constantly the same constantly in sync, that's kind of way to force it. You also want to give a quick shout out to this project, Pip DEP tree. Remember, Brian, we spoke about that before? Yeah, just pretty cool. And what it'll show you is this will show you the things you've directly installed, versus the things that happen to be installed. So if we go back to this like animation, here, you can see that it's got flask, which is 202. But then it's got Mark, safe, it's got it's dangerous, like nobody installed, it's dangerous. That's a thing that was installed because of flask. And so for example, when I look at my environments, there were some things that were out of date, but they were out of date, because they were pinned requirements of other things that I actually want to do install. So for example, example doc OPT, and some other things are pinned to lower versions, and I can't really update those, but they'll show up as outdated. So you might pair this with some PIP DEP tree to see like, what ones are you in control of? And what wants to just kind of out there?

00:06:51 That's pretty cool.

00:06:52 That's that one. What do you got for us?

00:06:55 Well, this is interesting, there's a discussion about a possible change to future Python. Again, this is just stuff that people are discussing. It's nothing that's even decided on. But it's a it's an idea of late bound arguments for Python, for late bound arguments for deep, or no late bound argument, defaults. That's it for for functions. So that here's the idea. So you've got this, we know that if you if you sign the default verb default value for function argument, that is bound at definition time. So when Python first goes and reads it, the, that seems fine. It's a weird thing about the naming the namespace there, though. So what happens is, if you have a variable foo, for instance, or a value foo, the value expression can be look, you can look that up in the defining area. So the namespace where the function is defined, it's a little specific, but it had it causes some weirdness, it's not the namespace of the function, it's the namespace of the surrounding the function. The problem with that really is that like, for instance, if we wanted to do something like a bisect function that took, you know, has has a, you give it an array, and maybe an x value for the middle or something, we also have a high and low, we know the low is index should be zero as a default. But what the high should be is should be the length of the array. And it's, you can't do that because you can't reference the array as a default value. So that's what this the kind of what this discussion is about, is trying to figure out a way to possibly have an optional late binding of those values. And in this specific case, it'd be very helpful to be able to late bind that value, like at the time that the function is called not at the time that it's defined. In this way,

00:08:56 you want to take the first parameter and use it to set the default value of the subsequent parameter.

00:09:02 Yeah, like to say like, the length of the array is the default for length or something. And that's the that was who was it? Chris and Jellico that suggested this. And the discussion actually got has some, some people even even Guido said, I'm not really opposed to let's, let's explore it a little bit. So there is some Chris is trying to do a proof of concept. There is some question about what the syntax was, should be. So Chris suggested a equal colon, so like the reverse of the walrus operator, because apparently that's available. Another suggestion was equal greater than to kind of look like an arrow but we already have like dash arrow to mean something else. So up in the air on the syntax, but anyway, one of the things I wanted to comment about is the in the article We're linking to it says at first blush and jello COEs idea to fix this wart in Python seems fairly straightforward. But the discussion has shown that there are multiple facets to consider. Oh, yeah. And it's always tricky to add complexity or to the language so that, you know, the people in the steering Council will take it. Think about it, right?

00:10:22 under consideration. Yes. Okay. Renee, what do you think about this,

00:10:26 I'm going to be honest, it's going over my head. I don't consider myself like a real software developer. So I usually use Python for, you know, standard data science type of scripts. I'm trying to sit here thinking of a use case for this that I would use and not coming up with one.

00:10:41 So yeah, I'm with you on that one as well. It's not doesn't mean, it's a bad idea necessarily. Well, what do you say, your good brain,

00:10:48 one use case would be to be able to set an empty list as a default value. You can't do that. Now, because the list is bounded. It all calls to the function will get whatever the last function set it to. And that's a weirdness in Python. But we could probably fix that with this.

00:11:07 Yeah, yeah. That's what I was thinking as well. If you pass immutable value as the default, then you're asking for trouble, right? Because if it gets changed anywhere, then every subsequent call gets those changes applied to it. So that seems useful this, like, sort of flowing one parameter to the next. I'm not sure it's worth the complexity. So Rene, what I wanted to ask you was, as somebody who doesn't dive deep into the, like, low levels of the language, and like compiler parsing and all that kind of stuff, which is totally fine. That's like 99% of the people. How do you feel about these kinds of new features coming along? Are you like, oh, geez, now I got to learn the walrus operator, I had to learn pattern matching, I was fine. And now I've got to deal with this code. What is this? Or do you see it as like, Oh, awesome. Here's new stuff. Yeah, I

00:11:53 mean, I guess it depends how much it really impacts my day to day work. If it's something that it's not impacting something I use frequently, or it's kind of abstracted away from me or optional, then, you know, go ahead. But if it's something that some, you know, some features they roll out clearly have wide ranging impact, and you have to go update everything. So I'm not great at keeping up with that, which is one reason that you know, of course, you'd be so careful when you update to a new version. But, you know, I guess that's why people listen to podcasts like this. So you know, it's potentially coming. So you're aware, I guess, so when it does come out? You're, you're on on top of it. But I don't have strong opinions. And what we worry about a lot in data science is the packages, right? So not the base Python, but the packages are constantly changing and the dependencies and the versions. So that's does end up affecting us when it follows through to that level.

00:12:45 Yeah, my my concern is around teaching Python, because every, every new syntax thing you put in, makes it something that you potentially have to teach somebody. And maybe you don't have to teach newbies this, but but they'll see it in code, so they should be able to understand what it is. So, but on the other hand, like things like, you can do really crazy. comprehensions list comprehensions and stuff, but you don't have to, and most of the ones I see are fairly simple ones. So I don't think we should Nix Nix shouldn't Nix something just because it can be complicated, anyway.

00:13:21 Yep, indeed. Yeah. Good. All right, Renee, you got the next one.

00:13:25 All right. So speaking of data science packages, a lot of us use pandas. So I wrote a book, which I'll come back to later called SQL for data scientists. And since I wrote that, and you know, some people that have been learning data science in school, or, you know, on the job, haven't always used SQL, or if they use it as kind of a separate process from their Python. So they started asking me how to use SQL alongside Python. So this is kind of beginner level, but also something that's just very useful in the pandas package, there's a read SQL function. And so you can read a SQL query, it runs the query, it's kind of a wrapper around some other functions, it will run the query and return the dataset into your data frame. And so basically, you're just running a query and the results become the data frame right in your notebook. So let's see some of my notes on here. So you can save your SQL as a text file. So you don't have to have the string in your actual notebook, which is sometimes useful. And then when you import it in from that Panda's data frame, that's where a lot of people do their data cleaning and feature engineering and everything like that. So you could just pull in the raw data from SQL and do a lot of the data engineering there. Sometimes I do feature engineering in SQL and then pull it in. So that's kind of up to each user. But you really just set up the connection in your database using a package like SQL alchemy. So you have a connection to the database, and you pass your SQL string, either directly or from the file and the database connection, and it returns a panda's data frame. So I'm happy to talk about little bit more about, you know how I use this at work.

00:15:03 I think this is really good. You know, one of the things to do with pandas is there's just so many of these little functions that solve whole problems. You know, it's like, oh, you could go and use requests to download some HTML. And you could use BeautifulSoup to do some selectors. And you could get some stuff and parse out some HTML. And then you could get some table information out and then convert that into a data frame. Or you could just say, Read HTML, table, bracket zero or whatever. And boom, you have it like knowing about these I think is really interesting. So it's cool that you highlighted this one I actually just an aside, I'm just literally like in an hour. So probably before this show ships will ship. This episode I did with Beck's toy he have about 25 Panda functions you didn't even know existed. And what's interesting is like this one, it wasn't even on the list.

00:15:53 So good. So I'll highlight another one now, you know exists. That's pretty

00:15:57 cool.

00:15:58 Let's see a couple of comments from the audience. Similarly, Sam says pandas is so amazing. Always find something too late, that it has all of these IO functions. And then we have Paul Antal. Hey, Paul says, Do you have any recommendations on tutorials for how to create good sequel alchemy? So collectibles? This always feels like the scariest bit.

00:16:19 I don't have any of that on hand. I'll try to find something later or I'll ask my Twitter following and see what they recommend. I don't have a good list of tutorials for that one. I can talk about Yeah, advice. Selectable he said he means connectable. So, yeah, I don't have a tutorial for that. There's a lot of documentation. And I know that sequel alchemy can be a little mysterious sometimes. Maybe that's why it's alchemy. But yeah, I will try to share that later on Twitter.

00:16:47 Yeah. Fantastic. Alright. And Paul says, Read clipboard is pretty great. Yeah. Yeah, very cool. But bunch of different things there.

00:16:54 So if you want me to walk through an example of how I use this at work, I'm happy. Yeah, give us give us a quick sample. Yeah. So at Helio campus, one thing we do is we connect to a lot of different databases at universities. So the universities will have separate databases for, you know, admissions, enrollment, financial aid, those are all separate systems. And so we pull all those all that data into a data warehouse. And in SQL, we can combine that data, build some extracts that we're all using the same way. And so we can either use this to just read one of those tables directly. Or we can combine, what I typically do is do a little bit of cleanup and feature engineering narrowed down my dataset to the population that I want to run through my model in SQL, and then just pull those final results. And now I've got my dataset with at least preliminary features, I might do some standardization and things like that in pandas. But I've got a pretty clean and subset of the data that I need. Right into my Jupyter. Notebook.

00:17:52 Oh, that's fantastic. Pretty great. Yeah, I think definitely understanding SQL is an important skills for data scientists. And it's slightly different than for say, like a web API developer,

00:18:04 right? Absolutely. That's,

00:18:06 that's awesome. Yeah, for sure. So on the API side, you kind of get something set up, you're very likely using an ORM, like sequel alchemy, and you just connect it and go. And once you get it set, like you kind of forget about it just program against it. As a data scientist you're exploring, you don't totally know, right? You're kind of out there testing and digging into stuff and sorting and filtering. And yeah, it's I think you need I would say, you probably need a better fluency with SQL as a data scientist. Absolutely. And as a web developer, because I can just use an ORM or ODM and just kind of know what it's doing.

00:18:37 Yeah. And it enables you to build your own data sets, instead of relying on a data engineering trying to explain what you need and why and which fields you need. Now, you could just do it yourself or, you know, out of field if you need it. You can do more sophisticated things like window functions. So yeah, I think knowing sequels is really a value add, if you're looking to become a data scientist, and, you know, putting yourself out there on the market. If you can do the whole pipeline end to end. It definitely makes you stand out.

00:19:03 I would think so. Alright, one thing to wrap up on this. Sam asks, Can you configure SQL alchemy to dump the raw query set? It runs? Yes.

00:19:11 Yeah. In this case, you have the raw query in your function call. So I'm not actually using SQL alchemy for that because you're saying like a select

00:19:20 statement, right? The problem with SQL alchemy and data science is you have to the structure of your models has to exactly match the structure of the data. And often I imagine you're just kind of dealing with loose data and doesn't make sense to take the time to like model it in classes. But firstly, welcome. You can just set echo equal true when you create the engine and then everything that would get sent to the crossover, the database gets echoed as like DDL or sequel or whatever. That it does. So yes, cool. Yeah. All right. Ryan, got our sponsor.

00:19:51 Yeah, let's look. I am pleased and happy to that shortcut is sponsoring the episode. So thank you shortcut formerly clubhouse for sponsoring the episode. There are a lot of project management tools out there. But most suffer from common problems like it's too simple for an engineering team to use on several projects, or it's too complex. And it's hard to get started. And there's tons of options. And some of them are great for managers, but bad for engineers, and some are great for engineers and bad for managers. shortcut is different. It's, it's built for software teams, and based on making workflows super easy. For example, keyboard friendly user interface. The UI is intuitive for mouse lovers, of course, but the activities that you use everyday can be set to keyboard shortcuts. If they aren't already, just learn them. And you'll, you'll start working faster. It's awesome type VCs integrations. So you can update tests progress and commits with a commit or a PR that sweep and iteration planning is a breeze. I like that there's a burn down and Cycle Time charts built in. They just are set up already for you when you start using this. So it's a pretty clean system. Give it a try at shortcut comm slash Python bytes. Absolutely.

00:21:06 They choke up for sponsoring this episode. Now, what have we got next year, pigeon, I want to talk about pigeon. So we already talked about Wilma, googan. And Rich. So it's time to talk about Anthony Sean so that we can complete our shout outs we always seem to give over on the podcast. So I want to talk about pigeon because I just interviewed Anthony Shaw. But more importantly, he just released pigeon as 1.0. So pigeon is a drop in JIT compiler for Python 310. Let me say that, again, a JIT compiler for Python. And there have been other speed up type of attempts where people will like fork C, Python, and they'll do something inside of it. To make it different. Think Cinder, there have been attempts to create a totally different but compatible one, like pi, pi, pi, pi, pi pi. And that's they've, they worked pretty well, but they always have some sort of in compatibility or something, it would be nice if just the Python you ran could be compiled to go faster, if you want it to be. So that's what this is it uses a pep whose number I forgot, that allows you to plug in something that inspects the method frames before they get executed. And then instead of just interpreting that code, the bytecode, as Python bytecode, it'll actually compile it to machine instructions, first to dotnet, intermediate instructions, intermediate language, and then those get compiled to machine instructions that then run directly works on Linux, Mac OS, Windows x 64, and arm 64. So this is a pretty cool development is pretty cool. Yeah. So if we go over here and check it out, too, in order to use it, it has some requirements, you just pip install pigeon. That's it. That's crazy, right? And then it has to be on 310. It can't be older than that. And you have to have dotnet, six installed. Okay, so that just got released, it's good chance, you don't have done that six installed. But then once you set it up, right, you can just say import pigeon, pigeon dot enable at the startup of your app, and then it will look at all the methods in JIT compiler. So if you come down here, like he has an example of a half function that Anthony put up here, and when it first load does not get compiled, but after that, you can go and say, if you run it, you can say disassemble this thing, and it'll show you basically, assembly instructions of what was would have otherwise been Python code. Well, it's wild, right? So it's a little bit like number, it's a little bit like a tiny bit like Cython, in the sense that it takes Python code, translates it into something else that thing can be interoperate with, and then makes it go fast. So this is all well and good. If you're going to use it on the web. By default, it would be just fine. Except if you're hosting it, normally, you host it in this, like supervisor process, and then a bunch of forked off processes. So there's a whiskey app configuration thing you can do as well, somewhere in the docs. I'm not seeing it right now. But you basically allow it to push the pigeon changes on down into the worker processes, which is pretty cool. And it has a bunch of comparisons against py, piston number IronPython, etc, UT Nootka, and so on. Now, it's not that much faster is faster when you're doing more like data science II things I believe, then if you're doing just like a query against the database, where you're mostly just waiting anyway, but still, I think this is promising and it's really pretty early days. So the thing to look at is if there's optimizations coming along here somewhere in the docs, they'll Anthony lists out the various optimizations he's put in so far, and really, it just needs more optimizations to make it faster still, which is pretty neat. I

00:24:50 think that's pretty cool. The one of the things that my first reaction was, oh, it's dotnet only so I have to use it on Windows. But that's not been that way. For a long time, so dotnet runs on just about everything. Yeah, exactly.

00:25:02 It supports all the different frameworks. There's even this thing called Live dot try pigeon comm where you can write Python code like over here on the left, and then you can say compile it. And it will actually show you the assembly that it would compile to. And then here's the dotnet, intermediate language, I guess maybe they should possibly be switching orders here. Like firstly goes to aisle and then it goes to machine instructions through the jet, but it shows you all the stuff that it's it's doing to make this work. And you can even see at the bottom, there's like, sort of a visual understanding of what is one of the things that's really cool that it does is imagine you've got a math problem up here, like you're saying, like x equals y times y, plus z times z, or you know, something like that, like, each one of those steps generates an intermediate number. So for example, z times z would generate a by default, a Python number. And then so it y times y and then the addition of finally assign it, what it'll do is it'll say, Okay, if those are two floats, let's just store that as a C float in the intermediate computation. And then that says, A C float. So it'll can, you can sort of stay lower level as a student, a lot of computation, all types of things. There's a bunch of interesting optimizations people can check this out. I haven't had a chance to try it yet. I was hoping to, but haven't got there yet. Yeah, really

00:26:20 interesting conversation you had with him, too. Thanks. And it's interesting timing to just get him to jump on this like, right after he right, wrote the book on Python internals, C Python internals, to jump into this. Right. Uh, well, I guess he's working on it before. But still,

00:26:37 yeah, it's, you definitely got to know C Python internals to do this. Renee, do you guys do anything to optimize your code with like number or Cython? or anything like that? Are you just running straight Python and letting the libraries deal with it? Yeah,

00:26:51 not currently, we have a pretty good server are working with relatively small datasets, you know, not millions of rows, for example. So for right now, we haven't gone in this direction at all. I can imagine this would also be really useful if you were a computer science student and trying to understand what's going on under the hood when you run these things. So it's interesting that it's the for the people that aren't seeing the visual, you kind of have three columns here with the code side by side to kind of get a peek under the hood of what's going on there. But now, this isn't something I've used personally.

00:27:23 Yeah, I haven't used it either. But like I said, I would like to, I think it's, it's got the ability to just plug in and make things faster. And really, it is faster. To some degree, sometimes I think it's slower, sometimes faster. But the more optimizations the JIT compiler gets, the better it could be. Right? So like, if you could inline function calls, rather than calling them or it could. There's things like, if it sees you allocating a list and putting stuff into it, it can skip some intermediate steps and just straight allocate that or, or if you're doing accessing elements by index out of the list, it can just do pointer operations, instead of going through the Python API's. There's a lot of a lot of hard work that Anthony's put into this. And I think it's it's pretty cool. Yeah, I haven't tried it. I would like to. Yeah. Cool. Indeed. All right, Ryan, what do you got for us?

00:28:12 Well, actually, before I jumped to the next topic, I wanted to mention I wanted to shoe into this last conversation. Brett cannon, just wrote a interesting article called selecting a programming language can be a form of premature optimization. And this is as relevant to the conversation because the real steps he says, if you if you think Python might be too slow, the another implemented Asian like pigeon is like step three. So first prototype in Python, then optimize your data structures and algorithms, and also like, you know, profile it. And then, and then try another implementation before you bend to Python all together. And then, you know, you can do some late bindings like language bindings, to connect to see if you need to arrest. But, but I think it ties in is like, when would I When would I choose pigeon or or pi pi over oversee Python? Well, it's step three, just to let people know.

00:29:12 Three, got it. Step three,

00:29:13 I wanted to do something more lighthearted, like use print for debugging. So I love this article. I am guilty of this, of course, I use debuggers and logging systems as well. But I also throw print statements in there. Sometimes, and I'm not ashamed to say it. So Adam Johnson wrote tips for debugging the print and that there were a couple that with print either with a couple that stood out to me I really wanted to mention because I use them a lot. Even with logging though, is a use debug variables with F strings and the equal sign so this is this is brilliant. It's been in since three eight, instead of typing like print widget equals and then with a string and then the widget number or something you You can just use the F F strings and do the equal sign and it interpolates for you, right? It doesn't interpolate. It just prints it for you. So it's nice like that. The next one is I love this. Use emojis. I never thought to do this. This is brilliant. Throw emojis in your in your in your print statements, so they pop out when your senior debugging if ever used emotional. I

00:30:23 started using emojis in comments. Okay, comments Nice. Yeah. So I'll put like the different emojis mean, for me, I was doing some API stuff. So like, this is a read only method here of an API. So I'll put a certain emoji up there. And this is one that changes data. So here's so I'll put there that here's one that returns a list versus a single thing. So I'll put a whole bunch of those emojis and stuff.

00:30:45 Yeah, well, I mean, I used to do like, all bunch of plus signs, because they're easy to see. an emoji would be way easier to see way more fun, man.

00:30:52 Yeah, yeah, yeah, I do this as well. I print all the time for debugging, especially in Jupyter Notebooks, because you don't always have the most sophisticated debugging tools in there. But being able to print and see what's going on going on as you go through each step of the notebook. And emojis are a great idea for that, because it's so visual, as you're scrolling through, you want us like the they're showing their the x and the checkmark emoji. I like that for my little to do lists and the comments that I leave. Yeah,

00:31:17 I thought so I've done that. And so it's cool. Chris May on the audience, just put a, you know, a heart sign, smiley face emoji as a response to this.

00:31:27 Last thing out, he's got like seven tips. The last tip I wanted to talk about was using rich and or specifically rich print rich dot print, or P print. So for P print, you have to do from P print installed P print, or something or unless you want to say it twice with P print dot P print. But it's for it's P print stands for pretty printing. And the gist of this really is the structures by default print horribly. If you just print like a dict, or, or a set or something, it looks gross, but Rich and Pretty print, make it look nice. So if you're debugging, printing with those and debugging, use that. So

00:32:08 yeah, there's also exception handling stuff in there for it. And there's a lot of that kind of debugging stuff and rich.

00:32:15 Yeah, printing exceptions is great with that. I also wanted to say one of the reasons why I, uh, one of the places where I use printing a lot for debugging is I print to print stuff in my what I expect is going on when I'm writing a test function, so I'll often print out the flow, what's going on. But the reason I do that is when if pi test for PI tests, if a test fails, pi test dumps the standard out, so it'll dump all of your print statements from the field procedure. So that's either the test under code or the test itself. Um, if there's print statements, it gets dumped out. So that's helpful. Yeah.

00:32:51 Nice.

00:32:51 That's great. I love it. I use print statements a lot. My output is very verbose.

00:32:56 You can see right in order what's happening, sometimes the debugger helps. But sometimes it's time to just print. Yeah, speaking of visual stuff, what's your last one here? Any?

00:33:05 Yeah, so in our line of work with data science, especially when you're providing the models as tools for end users that aren't the data scientists themselves, you really want the explainability is really important. So being able to explain why a certain prediction got the value it did, what the different inputs are, we're always working to make that you know, more transparent for our end users. In our case, for example, we might be predicting which students might be at risk of not retaining at the university, so not being enrolled a year later. So what are the different factors both overall for the whole population that are correlated with not being enrolled for a year, and for each individual student, what might be particular factors that, at least from the models perspective, puts them at higher risk. So this package is called shap. And that stands for Shapley additive explanations. It was brought to my attention by my team member Brian Richards at Helio campus. And now we use it very frequently because he has really good visualizations. So these Shapley values, apparently, they're from Game Theory, I won't pretend to understand the details of how they're generated. But as you can think of it as like a model on top of your model. So it's additive and all the different features. If you see the visualization here, it's showing kind of a little waterfall chart. So some of the values that you think of a particular row that you're running through your algorithm, some of the values in that row are going to make the if you're doing a classification model, some values might make you more likely to be on one class, some might make you more likely to be in the other class. So you have these visuals of kind of the push and pull of each value. In this visual we're seeing you know, age is pushing a number to the right sex is pushing it to the left, I guess BP and BMI at that looks like a blood pressure. So it's got this like waterfall type of chart and what is actually doing as a company herring, it starts with the expected value for the whole population. And then it's showing you for this particular record, each of the input values is kind of nudging that eventual prediction, one in one direction or the other. So it's just nice visually to have those waterfall plots, and to see which features are negatively or positively correlated with the, you know, the end end result. And you could also do some cool scatter plots with this. So you can do the input value versus the shot value and have a point for every item in your population. So for in our, in our example, that would be students, so we can have a scatterplot of all the students and something like the number of cumulative credits that they have as of a term. And so you'll see the gradient of like, from low credits to high credits, it's not usually linear. What are those kind of break points? And at what point are the values positively impactful to likelihood to retain, or in the opposite direction, of course, I'm glad that they put in this documentation, a whole, they have a whole section on basically, correlation is not causation. And we're constantly having to talk to our end users about that, that, you know, if we say, a student that you know, lives in a certain town is, you know, potentially more likely to retain maybe because of distance from campus, or maybe you have traditionally recruit a lot of students from that town, it doesn't mean that if you force someone to move to that town, they're more likely to stay at your institution, right? So yeah, correlation is not causation. And I'm going to switch over here to the visual to something called a bee swarm plot that you can output this right in your Jupyter notebook, which is really handy when you develop a new model. And I'll try to describe this for people who who are listening to the audio. It has along the x axis, a list of features. So you've got in this example, on their website, age, relationship, capital gain marital status, and then you see a bunch of dots going across horizontally. And there's areas where there's little clusters of dots. So what this is showing as the x axis is the shop value, so what this shop package outputs, so you can see visually across, you know, what is the spread of the impact of this value. So if each.is a person in this case, you see people all the way to the right, whatever their age was positively impacted their eventual score, people all the way to the left, their age negatively impacted the score. And then each.is, a color that ranges from blue to red. So the blue ones are people with low age, and the red ones are people with a high age. So you can see here, the basically, the higher the age, the more positive their eventual prediction. So just an interesting way to get both like a feature importance and see the distribution of the values within each feature. So it's just really helpful when you're doing predictive models, both for evaluating your own model and then eventually explaining it to end users.

00:38:08 So what a wider spread mean that the the feature is more useful, or, or does it have any?

00:38:16 Yeah, especially if you can see a split in the numbers there. So you see, in this example, relationship, you've got all the red ones to the right, and all the blue ones to the left, that means that there's, you know, a clear relationship from this relationship field with the target variable. So there's, there's a clear split, where you know, the low values are one side and the high values around the other side. And then yeah, the spread means that if there's, there's not a good example here, but sometimes you'll see like two clumps to be swarmed, spread apart with nothing in the middle. So that's when you have a really clear spread of the, you know, high impact group versus the low impact group. And if it's more narrow, that's less of a important variable, see, you see a few look at the one that's sorted by Max, here we go. Absolute value of the shop value, the ones near the bottom, for the population have less impact. Now there might be one person in there where that particular value was like the deciding factor of which class they ended up in. But for the population as a whole, there's less differentiation across these values, then across the ones near the top of the list.

00:39:25 Yeah, this is cool, because that visualization of models is very tricky, right? And it's something like knowing why you got an answer. This looks very helpful.

00:39:34 Yeah, it's really useful. And the visuals are so pretty by default, but then you can also pull those values into other tools so well, for example. So for each feature in each row, you get a shot value. So you can write those back to the database and then pull those values into another tool that we use it in Tableau, to highlight for each student. What are those really important features either making them, you know, if you're not making them it's not causation? correlated with, they're more likely to retain or less likely to retain. So we might say, well, for the student, their GPA, that's the main factor, their GPA is really low. Students with low GPAs tend not to retain. And so when the end users looking at all their values in, you know, in a table or some other kind of view, you can use the shot value to highlight the GPA is the one you need to hone in on the student is struggling academic, right,

00:40:26 try to help them get some help with grades, for example. Yeah, this is a great find. Indeed, indeed, Brian, that brings us to the extras, extras, extras for us. It do,

00:40:37 I've got one. That was just a quick one. Let's see, pull it up. Matthew feickert mentioned on Twitter, that PIP index is a cool thing. And I kind of didn't know about it. So this is neat. So PIP index is something that you can take PIP index, well specifically picks PIP index versions. So PIP index does a whole bunch of stuff. But PIP index versions will tell you if you also give it a package. It'll tell you all the different versions that are available on pi pi, and which one you have in which, you know, if you're at a date and stuff, but so for instance, if you're thinking about upgrading something, and you don't know what, what to upgrade to, you can look to see what else is there, I guess,

00:41:26 or you want to roll it back, you're like, oh, this version is not working. I want to go back to a lower one. But you're on two Dotto as it not one not what is it right, what do you go back to? And so this whole, like, list all the available versions? Basically, this is a CLI version of the releases option in pi pi.org. Right? And

00:41:44 that's not It's not like obvious how to get to on the on pi pi. But I know you can you can get to it, you can see all the releases, but by default, it doesn't show those. So this is pretty quick. Yeah. So you need

00:41:55 good one. Good one, Renee, how about you some extras?

00:41:59 Sure. I wanted to make sure to mention my book. So just published and just out in Europe this week, actually is a paperback by has been out since September in the US SQL for data scientists, a beginner's guide for building datasets for analysis. So I mentioned earlier, you know, I wrote this book, because I think a lot of students coming out of data science programs, or people who are coming from maybe a statistics background that are in data science might not have experience pulling the data. So in class, a lot of times you're given a clean spreadsheet to start with, when you're building your predictive model, then you get to the job. And you know, you sit down the first day, and they say, Great, build us a model. And you say, well, where's the data, it's raw form in the database. So you have to build your own data set. So that's what the purpose of the book is to kind of get you from that point of when you have access to raw data to exploring and building your data set so that you can run it through your predictive model. So on the screen there you see my website, and for for people on the audio, it's sequel for data scientists.com. And you can go to different chapters on the website, and I have some example SQL and you can also run it. So there's a sequel lite database, in in the browser here. And so you can actually copy and paste some of the SQL on the page. Click Execute, and it shows up in a table down here, you can edit it and rerun it. So you get a little bit of practice with this the using the database in the book. Neat.

00:43:24 Yeah. Cool book, and wow, sequel lite in the browser. Very neat. Thank you. Yeah. Awesome. It's a book that definitely should exist. All right, really quickly. I'm gonna do a web cast with Paul Everett. Haven't seen Paul in the audience today. Paul, where are you now? Not sure. You might be working. But on November 23, I'm going to be doing a webcast around pi charm. I've updated my PI charm course, with all sorts of good stuff. Haven't quite totally announced that yet. Because there's a few things I'm waiting, slightly more stable versions that come out of JetBrains to finish some of their data science tools, actually. And then I'll talk more about it. But we're doing a webcast in about a week or so. So that should be a lot of fun. And yeah, come Come check it out. Watch. Pardon me. Make the code go two days before Thanksgiving.

00:44:11 Yes, indeed. All right, that brings us to our joke. And in the joke, what is a response? Something that you posted on Twitter, really appreciating my foresight, using lots of stuff, comment as the message and get commit? Well, it

00:44:27 actually confused me because I did a git rebase mean, and it said applying lots of stuff. And I thought it was it. I thought it was like a feature of Git rebase. And it just happened to be my commit message.

00:44:38 As I go gets gotten real casual to lots of stuff. So Francoise Varane said time for a classic XKCD link here. Yeah, yeah. And so this is like the commit history throughout the project as you get farther into it. So it starts out with very formal, proper comments like treated me loop and timing control the next committers enabled config file parsing and then starts to fit miscellaneous bug fixes, and code additions and edits, and then a branch more code. You have code just eight letter A's. It comes back with screaming exactly just at KFJS lk just a bunch of home row. My hands are typing words, and then just hands in the title is, as a project drags on my Git commit messages get less and less informative. We've all been there, right? Yeah, yes.

00:45:37 I happens to be with branch names too, because I, if I'm working on one feature, and push part of it, and then I go, and I'm still working on it. I like to use a new branch name. And I just, I can't, it's hard to come up with good branch names for

00:45:51 I'm branching. Exactly. I try, I try to be more formal on the branches, at least. So I know, I can delete them later. And so when I'm working on projects that are mostly just me, I'll create a GitHub issue. And then create the branch name to be like a short version of the issue title and the issue number there, then when I commit back in, I can just look at the branch name and put a hash that number, and it'll tag it in the commit on the issue. And GitHub. If I'm working with someone like a team, I might put like my name slash branch name. And then actually in some of the tools like source tree, though, you have like little expando widgets around that on the branches. So you can say these are Michaels branches, and these are renamed branches. And so

00:46:32 yeah, we got into the habit of doing that too. It helps a lot to see right up front whose branches this?

00:46:37 Yeah, I can get can get out of control. Right. Alright. A quick couple of follow its brain. Anthony says the book looks great, Rene. I'll check it out. Great. Thank you. Chris. Me likes it as well. It's a great book idea. Especially when I keep working long after I should have gone. No, this is the joke. This is the especially after I keep working long after I got home. Thank god yeah, yeah, absolutely. And Sam, oops, forgot to stage this as a as a common message in my repositories.

00:47:05 Nice deed. So cool. It was fun episode. Thanks, Renee, for coming on.

00:47:11 Yeah, thanks for having me. It's fun. Don't get to dive into Python too often. I mean, I'm using the same type of things over and over so it's nice to see what's new and what's on the horizon. Awesome. Yep.

00:47:20 Thanks, Marcia. Day. Thanks, Brian. Y'all, bye

