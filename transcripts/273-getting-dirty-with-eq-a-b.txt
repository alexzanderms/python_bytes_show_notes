00:00:00 Hello, and welcome to python bytes where we deliver Python news and headlines directly to your earbuds. This is episode 273. Recorded March 1 2022. And I'm Brian Aachen. I'm Michael Kennedy. Welcome back, Michael. It's good to have us here. So it's great to see you see you as always, it feels like Spring is almost here. It's March. I can't believe it. So pretty awesome. Yeah. Button to be talking Python with you. Yeah. So to kick it off with your first item? Let's do it. I'm a big fan of science, math, and all those things. And I came across this article, because I was reading about science, not because I was reading about Python. But then I thought, oh, there has to be a Python story here. Let's get into it and see if I can track it down. And wow, was it not easy to find? So here's the deal, I saw an article over on science alert.com, called physics breakthrough as AI successfully controls plasma in a nuclear fusion experiment. That's so cool. Holy. That's amazing. Right. So let me put a few things together here, nuclear fusion, not fission. That's the kind of nuclear we want, that is harnessing the sun with no negative effects to like, turn hydrogen into helium and so on. Right? If we could harness that, that's like free, super easy energy forever. It's incredible, right? So people have been working on this for a long time, the way that I understand, which is probably pretty, you know, piecemeal that it works is you put some kind of thing, some kind of material like hydrogen or something in the middle, and then you blast it with tons of energy, but then it creates this plasma, you've got to control with lasers and magnets on how you basically keep the pressure high enough, in addition to just the heat to actually make the fusion work, right. So there's been some some success, like, Hey, we got fusion to work for a while, it just took more energy than it put out. So you know, it's not a super great power plant. But it did do the science thing, right? Yeah. So here's the deal. This article says they've used artificial intelligence to teach it how to make instantaneous or near instantaneous adjustments to the magnetic field lasers, in order to actually get better results with Fusion. Right, so take it farther along. And it says in a joint effort, the Swiss plasma center, and artificial intelligence research company Deep Mind, they used deep reinforcement learning to study the nuances of plasma behavior and control inside a fusion tokamak. That's the doughnut shaped thing that where the reaction happens, and they're able to make a bunch of small adjustments really quickly, in order to get better results. And it's pretty wild that they did that with AI, isn't it? Yeah, yeah, there's definitely Python in there somewhere, you just know it. Exactly. So I'm like, Alright, where's this? So I went through, and they talked about the findings being in nature, some of the articles that they're referencing, so there's some like deep, as in, not super engaging, and sort of scientific articles like the, you know, traditional academic style of writing that you got to dive into and then like, follow a bunch of links, but eventually, in there, you will find that there is some cool science stuff going on. And Python is at the heart of it. So it's probably not worth going into too much of the details of how it's actually happening. But it's the Python side of things, but I just thought it was super cool that, oh, here's one of the most exciting things happening in energy and for the climate and for all sorts of things. Yeah. And AI and Python are pushing it forward. That's crazy. And this is what we need for Mr. Fusion so that we can make a flying cars and, and in time traveling cars to exactly I mean, Marty McFly and Doc they go and they throw their their banana peel on the back of the DeLorean. Right. You've got to have one of these tokamaks to make it rolling. Gotta have Python. Yeah, far. Oh, come on, obviously. So cool.

00:04:01 All right. Well, take us back to something more concrete. Well, okay, so I'm pretty excited about this. It's a minor thing, but maybe not too minor. PEP 680 has been accepted standard track for Python 311. PEP, 680 is Tama lib support. So support for parsing Tommo in the standard library? We haven't had it yet. That's awesome. So it, we've got JSON, we've got CSV, why not write xml? Well, and one of the, and now that we we've PyPI uses Tommo for pipe project. automall. But, um, and anyway, so we kind of need I think it'd be cool to have in the standard library. I think it's fine to have other outside supports. So what what they're doing is, and if people don't, there's some rationale here, but, you know, just think it's easier than normal. So tamo is I like tamo for because it's just I don't know, it's you

00:05:00 format to read, it's better than any and some other stuff. And for people who don't know it feels any like, like the dot i&i file style, where you've kind of got like section headers, and then key value bits. Yeah, and it doesn't. And often it doesn't like you can use, you can use black and write a pipe project that tamo file without even really knowing anything about Tommo. So it's pretty straightforward. But we didn't have a way built into standard library to just use it. So that's this is this PEP. One of the things they're interesting bits about it is it's only reading, so we're only adding support for reading tombol. So there's a load and a load load s, so you can load a tahmo file, or you can load a string. And that's it.

00:05:49 And it outputs a dictionary. Um, so and that makes sense, you're just getting a terminal object and gate, turning it into to a dictionary, so you can use it.

00:06:02 But this is built on top of tomley. So tomley is being used as a as, as the, as the library to basically there's an open source project called tomley, which a lot of projects are using, I think this is the one that pi test is using, and quite a few projects are have switched to this. It's really fast. It's nice, but it supports like writing as well, but writing and code and Donbass and all this, yeah, right. So, but that's, that's not the part that's gonna get supported. And I think that's, I think that's fine. To just have reading built into, into Sure some file formats like text and, and CSV and whatnot, like reading and writing is super common, right. But these are way more likely to be used as configuration files that derive app startup and like hide secrets, you know, you put your secrets in there and don't put in Git or something like that. Whatever. Right? Those are the kinds of UK use cases I would see. And so in that case, reading, it seems fine. You can always add writing later. You just can't take it away if you add it too soon. Right. Right. But, but also like, I don't, I don't. And I'm sure there are reasons to need to write it. But I don't

00:07:17 you know, it's mostly people write it and computers read it sort of thing. Yeah, exactly. Some kind of editor writes it. And then you read it. Yeah. So fantastic. All right. Well, cool. Very nice to see that one coming along.

00:07:30 Alvaro out in the audience. Hello. There says Hummel just reached version 1.0 Not so long ago. So maybe that also has some kind of impact on the willingness like, alright, the file format is stable. Now we can actually start to support it in the library. That's true. And and we do support Python releases for a long time. So that probably needed to be v1, at least. So

00:07:55 NCM also says there's a lot of stylistic choices for how you write Hommel files. Like we need a black for Tommo. Not to drive tough not to configure black, but something that then goes against Tama files and makes them consistent. Yeah, maybe. Yeah, but you could, you could you could bake that in. Alright, what if I got next here? I've got sticking on the internals here. I want to talk about thread locals in Python. Okay, so last time we had Calvin on and I spoke about this crazy async running thing that I had built. And boy, is it working? Well. I like I said, it is truly horrifying to think about what it's doing. But it actually works perfectly. So there it is. But one of the challenges that it has, is it, it doesn't like it, if you call back into it again. And I talked about the

00:08:49 the nest async IO project last time, which maybe will solve it. I tried those and it wasn't working. But it could have been like at a different iteration before I finally realized like, No, I have to go all in on this. Ready and like isolate all that execution into one place where we can control it to maybe it would work. But I just wanted to talk about thread locals in Python, which I thought were pretty easy and pretty interesting. So I've got this stuff running over there. And one thing that would be nice is each there's different threads calling into the system to say schedule some work for me basically puts it on a queue, the queue runs it on this like control loop, and then it sends back the result. The problem is if if one function calls that to put in work, and then as part of doing that work, the function itself, somewhere deep down, like wraps that around it doesn't really like the recursion aspect very much. So what I thought as well, how do I figure out well, this thread has running work. And if it calls again, you know, raise an exception and say like, you need to adjust the way you're calling this library. It's not working right instead of just like doing some weird thing. So what I think I might do, and I'm not totally sure will work perfectly, but the idea is certainly useful for all sorts of things.

00:10:00 use a thread local variable. Now, when I thought about thread local variables, I've used them in other languages. And I had no idea how to do them in Python, it turns out to be incredibly easy, you just say go to threading the threading module and say local, that becomes like a dynamic class that you can just start assigning values to. So in the example that I'm linking to, it says, you get a my data thing, which is a thread, local, data, blob, whatever. So you can say like, my data dot x equals one, my data dot list equals whatever, and then that will store that data, but it will store it on a per thread basis. So interesting thread has sees a different value. So for example, what I could do is say, thread, you know, at the beginning of the call, like I have running work, yes, at the end, you know, roll that back. And if I ever call into schedule, some work, and the thread local says, I'm doing I have active work running well, there's that error case that I talked about. And they don't have to do weird things, like, put different IDs of threads into database into like a dictionary, and then like, check that then lock it and like all sorts of I can just say, this thread has like a running state. For my little scenario. What do you think? I think that's great. I think it's interesting. Yeah, it is, right. And it's right, not too hard. Just create one of these little local things, interact with it in a thread. And each thread will have basically its own view into that data, which I think is pretty fantastic. So

00:11:23 like a thread, version namespace thing. Yeah. Yes, exactly. Exactly. It's a cool little isolation, without doing like locks and all sorts of weird stuff that can end up in deadlocks or slowdowns or other stuff. So anyway, if you're got scenarios where you're doing threading, and you're like, I would be really great if I could dedicate some data just to this particular run and not like a global thing. Check this out. It's it's incredibly straightforward to use. But yeah. Oh, I let me pull up one more thing before we move on, Brian. Okay.

00:11:56 How about data dog? Yes, that's also something else that's extremely easy to use. Yep. Thank you data dog for sponsoring this episode. Data dog is a real time monitoring platform that unifies metrics, traces and logs into one tightly integrated platform. Data dog APM empowers developer teams to identify anomalies, resolve issues, and improve application performance. begin collecting stack traces, visualize them as flame graphs, and organize them into profile types such as CPU, io, and more. Teams can search for specific profiles, correlate them with distributed traces and identify slow or underperforming code for analysis and optimization bus with data dogs APM. Live Search, you can perform searches across all across the full stream of integrated traces generated by your application over the last 15 minutes. That's cool. Try data dog APM, free. With a 14 day free trial and data dog, we'll send you a free T shirt, visit Python bytes.fm/data dog, or just click the link in your podcast player show notes to get started. Yes, thank you data dog. I love all the visibility into what's going on. I was just dealing with some crashes and other issues on my something I was trying to roll out and some libraries conflicting with some other library they were fighting. And yeah, it's great to be able to log in and see what's going on. Now before we move off the thread, locals quick Audience Question Sam out there says it might be better to use context VARS. If you're also working with an event loop, as far as I know, context, bars are the evolved version of thread locals that are aware of async two. That's very interesting. I haven't done anything with context bars. But the way I think async IO works is even though there's a bunch of stuff running from different locations, it's there's one thread so thread locals useless for that. So that's why Sam is suggesting context. Where's the side that schedules the work has nothing to do with async IO in my world? So that's why I was thinking thread local. Hmm. It's a good, good highlight to say if you're using async, you may not you may need something different. Absolutely. Yeah. So thanks. Thanks, Sam, for that. Yeah, so I'm not sure if we've really talked about much, but I've got I came across that article from Trey Hunter called what is a generator function. And like Python, especially, you know, the the two to three switch, even like, dictionary, the items keyword, you know, function to get all the dictionary elements out. It doesn't return a list anymore, returns a generator. And, and maybe, I don't know, but there's a whole bunch of stuff that used to return lists now return generators, and it kind of they like they work great. You stick them in a for loop, and you're off to the races. But a lot of people are a little timid at first to try to write their own because it's a yield statement instead of a instead of return and what do you how do you do it? And so this is a great article by trade to just say

00:15:00 Here's what's going on, it's not that complicated.

00:15:04 Generally, you just have, you often might have a for loop within your code. And instead of returning all the items you one by one yield of the items. So, trade goes through some of the more deep some of the details of like how this all works. And it's, it's pretty interesting. It's, it's interesting for people to read through it and understand what kind of what's going on behind the scenes. So what happens is your, your function that has a yield in it, it will not return the item right away. When somebody calls it, it returns a generator object. And that generated object has things like next. And mostly, that's what we care about. And next returns the next item that you've returned. And then once you run out items, it raises a stop iteration exception. And that's how it works. But generally, we just don't care about that stuff. We just throw them in a for loop. But it is interesting to learn some of the details around it. Yeah, they're they do seem mysterious and tricky, but they're super powerful, the more data that you have way better idea it is to not load it all into memory at once. Yeah, and you can do some fun things like

00:16:15 chunking, you can you like if you're returning, like your your color, like let's say in this, these are fun things to do with this. So let's say you're you're reading from an API or from a file or from a device or something, and

00:16:30 it has you read like a big chunk of things, like 20 of them, or 256, or something like that a whole bunch of data at once. But then your color itup, your color really only wants one at a time. It within your function, your generator function, you can do fancy stuff, like read a whole bunch, and then just meter those out. And then when then that's empty, go and read some more and have intermittent reads. And this will save time for especially when you're not, you're not reading everything, often, sometimes the color will break and not utilize everything. So that's definitely where and they're very, they're a lot more efficient on memory, too. So if you're like you said, if it's huge amounts of things, it might be either for memory reasons, or for speed reasons. These are great. Yeah, so yeah, even computational, like suppose you want a list of Pydantic objects back and you're like reading some massive CSV and picking each row and star star value in there somehow.

00:17:27 That's the actual creation of the Pydantic object. If there was like a million of them, forget memory, like even just the computation is expensive. So if you only want the first 20, like you can only pay the price of initializing the first 20. So there's, there's all sorts of good reasons. Yeah. Okay. I do want. I do want to just say one thing about generators that I wish there was like a slightly PB some kind of behavior could be added, which would be fantastic. So generators can't be reused. Yeah. Right. So if I get a result back from a function, I try to, I want to ask a question like, were there any items resolved in here and then loop over them, if there were, like you, you kind of broke it right? You've pulled the first one off. And then the next thing you work with is like, index one through n rather than zero through N, which is a problem. So sometimes you need to turn them to a list, it'd be cool if there was like a.to list on a generator. Instead of having to call this diner. I just like a way as an expression to kind of like I'm calling this and it's sort of a data science flow. I want all one expression and turn this generator into this other thing that I need to pass a law. That would be fun.

00:18:34 Yeah, so question out in the the audience that maybe they they returned, that the dictionary items and keys returned something different. But Sam morally says they they returned special generators, special kinds of generators. So yeah, thanks, Sam. Well, indeed.

00:18:54 All right. Well, what if I got on next? I think it was closed it. Now would it really be an episode if we didn't talk about Wilma Coogan in some way or another? So we got him on deck twice, but we're gonna start with just something he recommended to us. That's actually by Sam Colvin, who is the creator of Pydantic. And now if you're not sure if you're ready for this, Brian, but this is a little bit dirty.

00:19:18 It's called Dirty equals, in the idea is to abuse the Dunder EQ method, mostly around unit testing. To make test cases and assertions, and other things you might want to test more declarative and less imperative. So that sounds like fun, but how about an example so it starts out with a trivial example. It says, Okay, from this library, you can import something called is positive. So then you could assert one or like, some number and whatever. One equal equal is positive. That's true, that assert passes. Negative two equal equal as positive bales. Okay, okay. How does that strike

00:20:00 Right.

00:20:01 Here, these are building blocks. This is like a Lego piece, not the whole X Wing. Okay, fighter. Okay. But anyway, so that's the building block, right? Like, take something instead of saying yes, it's exactly equal, implement the Dunder equal method is positive class to like, take the value, make sure it's a number, then check whether it's greater than zero, right? That kind of thing. I don't know if that includes zero. But anyway, but then you can get more interesting things like so you could go to a database. And if you do a query against the database, you get I think, in the case that's up there, I think you get a tuple back, it depends on what you set the row factory to be, I suppose. But anyway, you get a tuple back of results, it looks like maybe this is a dictionary anyway. So then you can create a, a dictionary that has attributes that are like the result you want, they can either be equal, or they can be things like this is positive. So in this case, we're doing a query against the database. And then we're looks like there's maybe needs to be like a first one anyway, says, All right, what we're going to do is we're going to do equal equal that. The ID. So we'll create a dictionary ID colon is positive int. Username, colon, Sam Colvin, so that's an actual equality, like the username has to be Samuel here. Okay. Yeah. And then the avatar is a string that matches a regular expression. That's like, the number slash PNG, the settings has to be a JSON thing, where inside the settings, it's got some JSON values that you might test for, and that is created now is now with some level of variation, like some level of precision that you're willing to work with, right? Because obviously, you run the database query, and then you get the result. But it's like, very near, nearly now. Right? It's like the almost equals and float type of stuff. That's pretty cool. Right? Ah,

00:21:56 do I didn't do any the answer? I mean, I could see the utility share your thoughts. Yeah. But the I don't know, it's the API's a little odd to me. But okay. Yeah, I think it's, it's definitely an interesting idea. It's definitely different. You know, Pydantic is often about, and it was not Pydantic. But it's by the Creator Pydantic is often about

00:22:19 given some data, that kind of matches, can it be made into that thing? And I feel like this kind of testing is in the same vein as what you might get working with Pydantic. And data. Yeah, right. Well, it's definitely, it's definitely terse, and, and, and useful. So, and I could totally get used to it. If this is, this is a pretty, pretty condensed way to, to compare to see if everything matches this protocol. Yeah, yeah. So Sergey on the audience has, like sort of the alternative perspective could be, you could just write multiple assert statements, instead of creating a dictionary that represents everything. You could say, like, get the record back and assert that you'll get the first value out and assert on it, then get the username out and assert and get the avatar and assert on it, and so on. And it's sort of an intermediate view story, where you use the testing libraries, the testing classes, but sort of more explicit, so right, and one of the reasons why a lot of there's there's a couple reasons why to not use more than one assert, because if you were to have multiple asserts the first one that fails, stops the check, it's possible that this will tell you everything that's that's wrong, not just the first thing that's wrong. Yes, exactly. And, and then, you know, some people are just opposed to multiple asserts per test, just for, you know, yeah, I don't know. It's similar things. So I have a plugin called PI test check. Which is, is just, it uses checks instead of asserts so that you can have multiple checks per test, but

00:24:01 it does come up. So this is interesting. I definitely check it out and play with it. Yeah, another benefit of being able to construct one of these, like prototypical documents, or dictionary dictionaries that then represents the declarative behavior or state that you're supposed to be testing for, is you could create one of these and then use it different locations, like okay, when I insert a record, and then I get it back out, it should be like this. But also, if I call the API, and it gives me something back, it should also still pass the same test. Like you could have a different parts of my app, they all need to look like this. Yeah. As opposed to having a bunch of tests over and over that are effectively the same. And Will is here who recommended this suggests one of the benefits of dirty equals is that pi test will generate generate useful diffs from it. Yeah, and definitely reasons bit pi tests being a reason to use something. I'm on board then. Yeah, sure.

00:24:58 Yeah, check it out. If you do play with it.

00:25:00 Give us a report How about one more question from Sam said Sam Morley pi test already has something a bit like this with approx except for it's for floods etc except for approx is not etc it's just for floats so you can only use approximate floods. So yeah, so we've like approximate now and stuff like that. So is it I'll try it especially you know if we'll likes it it's got to be good.

00:25:29 Exactly.

00:25:31 So awesome. All right, what's the final one you got for us here? Okay, this is more of a question than a I'm not like saying this is awesome, but I ran across this. Actually, this. I went, I clicked on a listicle my I think there's a self help group for that. Yeah. Well, we're definitely

00:25:51 prone to clicking on the top. Yeah. listicles. So my name is Matt and I clicked on a listicle. Um, so the the list goal was top 10, or we had was a 10 tools. I wish I knew when I started working with Python, and actually, it's a good list, I just knew about most of them as well. So it's, it's, it's a We'll link to it anyway, it's got the sound of music, it's got Jackie Chan, it's got office space, come on, this is a pretty solid listicle what's good, and I got down to number seven, and eight. And I'm like, What are these things I've never heard of them. So commit a sin and Symantec release. So

00:26:27 the idea so I tried to do a commit with this. So committed sin is a thing that you can say if you install it, you can either brew install it for your everything, or you can put it in a virtual environment. So that's cool. But it's um, you you, instead of just committing you use this to commit and it asks you questions, right? Instead of typing get space commit, you type CZ space commit, yeah. And then instead of like, it asked you a whole bunch of stuff, was this a bug this fix? Was it a feature? Did you and then it follows on what depending on what you answered, If you had, if you had a bug fix or a features at a breaking feature, did you basically it's trying to, it's doing a whole bunch of stuff, but it's trying to do these conventional, conventional commits. And we've got a link to this too. And, and then if you've got all this formatting, so it ends up formatting your commit message to a consistent format, so that when you're reading the history and stuff, ELCO, you can do a whole bunch of it's easier to guess. And then this tool, also, this listicle also commented that you've got Symantec released, which is a Python package that I haven't got through this much. But it can take this

00:27:45 all this information from these and do some better control years Symantec release notes or release. I don't know if it's the release notes, or just the release version. Haven't got that far into it. But yeah, the commit is an ask, is this like a change corresponding to semantic versions? Such that should be a major change. So it'll like it looks like it'll increment the version and stuff like that as well. Yeah. Yeah. Um, but so the in the about, for comparison says, command line utility to create commits with your rules. And apparently, you can, you can specify some special rules, which is good. display information about your commits, bump the version automatically and generate a change log. That's cool. I want that might be helpful. So my questions out to the audience and everybody listening?

00:28:35 Have you used something like this? Is it useful? Is there something different than this that you recommend? And also what size or project with this makes sense for a smaller medium project? That's cool. Yeah, let us know on Twitter or at the bottom of the YouTube livestream? Yeah, best place. So yeah, very cool. Now, before we go on, also have a question out to you. You can be the proxy for the audience here. Notice at the bottom, it says requirements, three, six and above. Right. Yeah, Python, let's not, I don't feel like that's very controversial. As three six is not even supported anymore. Right. Right. So this is like, every possibly supported version of Python three, this works for wood. What would you think if I said, the requirement? Is this is python three? Not python three? Is it just it requires python three, knowing that, like that means or implying that that means supported shipping real versions of Python? Not Python? Three, one, right? Because obviously, python three one is no longer supported, but neither is three, five, even like could you say F strings or just in python three now without worrying about the version? Or do you need that you still need to say through six plus three six through 10 Like should this be updated? B three, seven, you know, I mean, it kind of have to think so. I don't know. I I know I when I say

00:29:51 something is on three python three. Actually, I don't even say that anymore. So yeah. What do you think? Okay, ah, well, I used it in

00:30:00 Since like, yeah, you need python three for this thinking, well, any version that's supported these days and people like, well, there's older versions that don't support this thing like, well, you know, obviously, I'm not talking about the one that was not supported five years ago, like, at some point, yeah. python three is the supported version of Python. I didn't Oh, that's true.

00:30:20 Okay, that's a bit of a diversion there. But I went down that route, hold on a sec, I really don't know which way I should go. But I feel like there's there's a case to be made that just like, when you talk about python three, you're not talking about old unsupported versions. You're everything that's like modern three, seven and above. Should it be like an S n, an alias for python three. I don't know, when we were just saying python three, what we meant was like three one. So I know we got to get used to that. There's no Python t really? Yeah. Don't worry about. All right. Well, that will definitely bring us to our extras. Yeah, yeah. All right.

00:30:55 You want to kick it off? Since I got my screen up? Yeah, go ahead. Alright, so we'll like I said, he gets to appearances. And also comments. Thank you for that. And this is like in the same vein of what I was just talking about, like, what is this convention that we want to have? Right? So the walrus operator came out in three, eight. And it was kind of an interesting, big deal, right? There's a lot of debate around whether or not that should be in the language. Honestly, I think it's a pretty minor thing that that's not a huge deal. But the idea is, you can both test for a variable as well. Or you can use the test or use the value of variable in the same place that you create it. So instead of saying x equals get user, or like you equals get user, if user is not none or if user, you could just say if you call an equals get user, do the true thing. Otherwise, then it's it's not set, right? And so will a suggesting that we pronounce the walrus operator as you becomes the value. So like, x colon equal seven is like x becomes seven. What do you think? Are you behind this? Okay? So you'd be like, when you're reading your code to yourself, I guess how do you say like, if you say, like, the lambda expression, like how do you like define like that? The variables of the land, right? Like there's there's right terms around there that are make it a little bit hard to say without just saying syntax, right? So he's proposing like, becomes is the same? The verbal the way we verbalize warsop? Right.

00:32:23 I might give it a thumbs up. It's interesting. But what how is that different from assignment though? Do we you said, What do you say with assignment? I don't say like x is equals, I don't know. Yeah. Equals, assign become becomes works.

00:32:38 I will put it out there. People can think about it. And there's a there's a nice Twitter thread here with lots of comments. So folks, jump in, or you just walrus just talk X walrus five. Oh, yeah. Well, what a walrus is do I mean, is there like a cool action that would is like, particularly lorises? Well, there probably is, but it's doesn't apply to the eye. It's not a very colloquial as it

00:33:04 is x. Yeah. And John, the John Sheehan audience says in my brain I use assigned to, and he must know what's coming, because he's up next.

00:33:16 Hey, John. So the other thing I want to talk about is Did you know, I learned through John, that string starts with will take a, an iterable. It's a tuple. But I suspect it might even be an iterable of substrings. And if any of them match, it will, it'll test out to be true. So like, ABCDEF, you say, starts with a tuple, A, B, or C, D or E, F. Ah, I've never used this. I didn't know that. That was I would always just do that as like, X starts with a B or x starts with C, D or x starts with EF No, you can apparently can do that all in one go. What's the two four? Um, I have no idea. Okay. I was just thinking that as well. There's a two and I don't know what it's for.

00:34:01 So, yeah, yeah. Anyway, that's a super quick one. But I thought pretty interesting there. Yeah. That's all I got. About you. I just have one thing, but I don't need to put it up. But I my extra is this book. Oh, you have your physical 2.0 book in hand? Yes. I've got it. Oh, yeah. And for the people not.

00:34:24 Not watching my I've got a stack of it's funny my my daughter uses my Amazon account to so UPS said, Hey, there's a package arriving yesterday. And I said, I didn't order anything. So I said, I told my daughter, hey, you probably have a package showing up. She's like, I didn't order anything.

00:34:45 And then this box arrives with five copies of my book, which is great. That's awesome. Congratulations. Thanks. Very cool. Yeah, we abuse our Amazon account badly. Like there's a lot of people that log into Amazon accounting, we end up getting stuck

00:35:00 wrong places because somebody shipped it to them last time, and then we just hit reorder again. And like, Why do you have our shampoo? I don't know. Yeah.

00:35:08 So John adds that the two is the starting position of the starting position. Yeah, I figured had something to do that. I wasn't sure how many characters to compare. Well, I also didn't know if the that you could pass a starting position for starts with. That's cool. Yeah, there's a lot going on here. Almost starts with all Yeah, nearly starts with Yeah. What's the what's the nearly what's the right way? So I want to close this out with a joke, as always. But there's the joke we talked about a while ago, where's Sebastian Ramirez, creator of fast API, saw an ad hiring a fast API developer and he said, Oh, it looks like I can apply for this job. It requires four years of experience with fast API, but I can't possibly have that because I only created it two years ago, right? Yeah.

00:35:59 So it's a little bit in that vein. So here we have somebody tweeting and says, Here's a conversation with the recruiter and then it says, recruiter, do you have a CS background? Yes, absolutely. My CS background. And this is a screenshot from the game Counter Strike, which is referred to as just CS. Yeah, of course, I got a CS background. You kidding me?

00:36:22 That's pretty good. I love it. Yeah. Oh, yeah. That's a good one. Well, just a question, though. If you if you did fast API, instead of eight hours a day if you did it 16 hours a day for two years would that constitute you know, years that probably that probably is about the same amount of experience? Yeah. So what a slacker that is, because you have to eat or something if family what's going to come on?

00:36:49 Well, always fun with hanging out with you and talking Python. So you bet. Thanks, everybody on the listens to it on on their podcast player or watches us on YouTube? Yeah, absolutely. See you later. Bye.

